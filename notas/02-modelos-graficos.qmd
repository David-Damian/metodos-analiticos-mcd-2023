# Modelos gráficos probabilísticos

```{r}
#| code-fold: true
#| warning: false
library(tidyverse)
library(kableExtra)
library(DiagrammeR)
ggplot2::theme_set(ggplot2::theme_light())
```

En problemas que no son muy simples, para hacer inferencia usamos modelos probabilísticos. En esta parte veremos una manera de visualizar estos
modelos que 

- Clarifica los supuestos que estamos haciendo.
- Hace más simple entender qué asociaciones esperamos encontrar entre sus
componentes.

Antes de hablar específicamente de problemas de inferencia causal, introduciremos
notación y repasaremos algunos conceptos de probabilidad multivariada.

## Repaso de probabilidad

Si $X$ es una variable aleatoria, abusaremos de la notación escribiendo
$p(x)$ para denotar su función de densidad (continua o discreta). 
Si $X$ es discreta, 
$p(x)=P(X=x)$, y si $X$ es continua, entonces $p(x)$ es la función de densidad,
que utilizamos para calcular probabilidades usando integrales, por ejemplo

$$P(X \in [a,b]) = \int_a^b p(x)\, dx$$
Ojo: en algunos casos, para evitar reescribir fórmulas, usaremos esta misma notación para denotar probabilidades 
de variables discretas, que más apropiadamente escribiríamos como
$P(X\in[a,b]) = \sum_{x=a}^{b} P(X = x)$.

Si $X$ y $Y$ son variables aleatorias, entonces denotamos por $p(x,y)$
a su densidad conjunta. Podemos calcular las distribuciones de x y y
integrando sobre una de las variables

$$p(y) = \int_{-\infty}^{\infty} p(x,y)dx = \int p(x,y)dx$$
Nótese que abusamos algo de la notación quitando los límites de la integral
de la derecha (y recordamos que si $X$ es discreta, entonces usamos una
suma en lugar de una integral). En este contexto, $p(x), p(y)$ se llaman
distribuciones *marginales* de $X$ y $Y$ 

Denotamos por $p(y|x)$ y $p(x|y)$ a las densidades condicionales
de Y dado X y X dada Y respectivamente. Estas están definidas por

$$p(y|x) = \frac{p(x, y)}{p(x)}$$
Esta densidad condicional nos dice cómo se distribuye $Y$
cuando sabemos que $X=x$.

De esta definición, tenemos la *regla del producto* que establece 
que 

$$p(x,y) = p(y|x) p(x) = p(x|y)p(y) $$

Cuando la distribución condicional de $p(y|x)$ cambia
dependiendo de la $x$, decimos que $X$ y $Y$ está asociadas. Si
no es el caso, decimos que son *independientes*. Esto quiere decir que

$$p(y|x) = p(y)$$
es decir, la condicional de $Y$ dada $X$ es igual a la marginal de $Y$. Por
definición, la independencia también se puede escribir como una versión
simplificada de la regla del producto:

$$p(x,y) = p(x)p(y)$$
es decir, la conjunta se factoriza en una parte que sólo depende de $x$ y
otra que sólo dependen de $y$.

::: {.callout-tip}

Una manera útil de construir modelos de probabilidad conjuntas con
variables que tienen dependencias es utilizando una factorización
de la regla del producto, lo cual nos permite concentrarnos en una
variable a la vez.

:::

Dependiendo del tipo de problema, puede ser más conveniente definir
$p(x)$ y $p(y|x)$ o $p(y)$ y $p(x|y)$. En ambos casos podemos calcular
la conjunta $p(x,y)$ con la que podemos calcular cualquier probabilidad
conjunta de interés o cantidad resumen que involucra a a estas dos variables
aleatorias.

### Ejemplo 1 {-}

Supongamos que $X$ es el resultado de una tirada de dado, y
que $Y$ es el número de soles que obtenemos en $X$ volados de una moneda justa.

Entonces podemos escribir $p(x) = 1/6$ para $x=1,2,\ldots, 6$,
es decir, $X$ es Uniforme en $\{1,2,3,4,5,6\}$, y 
$Y|X=x$ son el número de soles en $x$ volados, de modo que
es Binomial con parámetros $(x, 0.5)$. Esto lo podemos escribir como

\begin{equation} 
\begin{split}
Y|X \sim & Bin(X, 0.5) \\
X  = & U(\{1,2,3,4,5,6\}) 
\end{split}
\end{equation}



Estas variables no son independientes, pues la condicional de
$Y$ cambia dependiendo del valor que toma $X$.

Como estas dos variables son discretas, la conjunta puede escribirse
con la regla del producto
como una tabla como sigue:

```{r}
probs_x <- tibble(x = 1:6, p_x = 1/6)
probs_conjunta <-  crossing(probs_x, y = seq(0, 6, 1)) |> 
  mutate(p_cond_y = dbinom(y, size = x, prob = 0.5)) |> 
  mutate(p = p_cond_y * p_x) #producto
probs_conjunta |> select(x, y, p) |> 
  pivot_wider(names_from = x, values_from = p, names_prefix = "x=") |> 
  kable(digits = 4) |> kable_paper()
```

Nótese adicionalmente que la forma en que planteamos el problema
naturalmente nos da un *modelo generativo*, es decir, podemos
simular fácilmente realizaciones de esta conjunta particular:

```{r}
simular_juego <- function(n = 1, x = NULL){
  if(is.null(x)){
    x <- sample(1:6, n, replace = TRUE)
  }
  y <- rbinom(n, x, prob = 0.5)
  tibble(n = seq_len(n), x = x, y = y)
}
set.seed(880)
simular_juego(n = 5)
```

Y usando simulación podemos estimar cualquier cantidad de interés
acerca de las variables $X$ y $Y$. Por ejemplo, su correlación 
la estimamos con

```{r}
simular_juego(n = 10000) |> select(x, y) |> cor()
```


### Ejemplo 2 {-}

Supongamos que $W$ es una el peso de una persona y $H$ su estatura. 
Podemos comenzar con la factorización $p(w,h) = p(h)p(w|h)$. Un modelo generativo 
podría ser el que 
sigue: $H$ es Normal con media 165 y desviación estandar 12, 

$$H \sim N(170, 12) $$

y dada la estatura $H=h$, el peso es

$$W|H=h \sim N(m_h, 10)$$
donde 

$$m_h = -50 + 0.7 h$$
```{r}
sim_wh <- function(n = 10){
  h <- rnorm(n, 170, 12)
  m_h <- -50 + 0.7 * h
  w <- rnorm(n, m_h, 10)
  tibble(w = w, h = h)
}
```

```{r, fig.width=5, fig.height = 3}
set.seed(992)
sims <- sim_wh(500)
ggplot(sims, aes(x = h, y = w)) + geom_point()
```
También escribimos este modelo en [stan](https://mc-stan.org/):

```{r}
mod_peso <- cmdstanr::cmdstan_model("../src/peso_estatura.stan")
print(mod_peso)
```

```{r}
datos_lista <- list(N = 500)
ajuste <- mod_peso$sample(data = datos_lista, refresh = 1000, fixed_param = TRUE)
sims <- ajuste$draws(c("h", "w"), format = "df")
resumen <- ajuste$summary(c("h", "w"))
resumen |> select(variable, mean, q5, q95)
```

```{r, fig.width=5, fig.height = 3, warning=FALSE}
ggplot(sims, aes(x = h, y = w)) + geom_point()
```



## Caso multivariado

Supongamos que tenemos $X_1,\ldots, X_p$ variables aleatorias. Denotamos su
conjunta con 
$$p(x_1, x_2, \ldots, x_n)$$
En el caso particular de 3 variables p(x,y,z) la regla del producto se
escribe como

$$p(x,y,z) = p(z|x,y)p(y|z)p(x)$$
que podemos escribir, dependiendo del problema, en cualquiera de las seis permutaciones
posibles, por ejemplo:

$$p(x,y,z) = p(x|y,z)p(y|z)p(z)$$

El proceso de simulación lo podemos mostrar gráficamente como sigue:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    X 
    Y 
    Z
  edge [minlen = 3]
    Z -> Y
    Y -> X
    Z -> X
{ rank = same; Z; Y }
}
", width = 200, height = 50)
```


Nótese que este ejemplo puede aplicarse a cualquier conjunta nos interese, pues
la factorización resulta de la regla del producto.

### Ejemplo

Supongamos que escogemos al azar un número $X$ entre 0 y 1, y luego tiramos dos veces 
cinco volados con probabilidad de sol $X$. Medimos el número de soles en cada prueba como $S_1$ y $S_2$.

En este caso, es natural escribir la factorización:

$$p(x,s_1,x_2) = p(s_2|s_1,x)p(s_1|x)p(x).$$
Sin embargo, podemos simplificar aún más esta conjunta, pues en realidad una
vez que sabemos X, el resultado de $S_1$ no cambia la distribución
de $S_2$, de forma que para el proceso que describimos arriba,

$$p(x, s_1, s_2) = p(s_2|x)p(s_1|x)p(x).$$
En este caso, en nuestros supuestos está la independencia condicional de $S_1$ y $S_2$ dado
$X$, que explicaremos con detalle más adelante. El diagrama relevante es

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    X 
    S1 [label = <S<SUB>1</SUB>>]
    S2 [label = <S<SUB>2</SUB>>]
  edge [minlen = 3]
    X -> S1
    X -> S2
{ rank = same; S1; S2 }
}
", width = 200, height = 50)
```


Y podemos hacer simulaciones de este proceso generador:

```{r}
simular_dos <- function(n = 10, x = NULL){
  if(is.null(x)){
    x <- runif(n)
  }
  s_1 <- rbinom(n, 5, prob = x)
  s_2 <- rbinom(n, 5, prob = x)
  tibble(x = x, s_1 = s_1, s_2 = s_2)
}
set.seed(116)
sims_monedas <- simular_dos(5000)
head(sims_monedas)
```
Nótese que aún cuando simulamos independientemente $S_1$ y $S_2$ una vez
que tenemos el dado, $S_1$ y $S_2$ no son independientes:

```{r, fig.width=5, fig.height = 3}
ggplot(sims_monedas, aes(x = s_1, y = s_2)) + geom_jitter(width = 0.25, height = 0.25)
```
- Cuando no conocemos $X$, saber $S_1$ nos da información acerca de $S_2$, porque
saber $S_1$ cambia la distribución de $X$ (cuál es la probablidad de sol)
- Si no conocemos $X$, la información puede *fluir* de $S_1$ a $S_2$.

### Ejemplo

Regresamos al ejemplo de estatura y peso. Supongamos que agregamos una variable
adicional $S$ que vale 1 cuando la persona es hombre y 0 si no. Podemos discutir
distintas maneras de construir nuestro modelo, por ejemplo, supongamos
que usamos:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    S 
    H 
    W
  edge [minlen = 3]
    S -> H
    H -> W
    S -> W
{ rank = same; S; H; W }
}
", width = 200, height = 50)
```


En este caso, para definir nuestro modelo generativo
tenemos que definir $p(z)$, $p(h|z)$ y finalmente $p(w|h,z)$.  En
este caso, consideramos que además de que los hombres tienen estatura
mayor y por tanto mayor peso, existe un efecto adicional
que, entre hombres y mujeres de la misma estatura, los hombres
tienden a ser más un poco más pesados.

- Entender la diferencia y cuantificar el efecto de hombre-mujer sobre peso a través de estatura y el efecto *directo* es importante y veremos cómo hacerlo más adelante.

En este modelo, podríamos argumentar que hay, por ejemplo:

- Muchas causas de sexo que podríamos considerar, pero no nos interesan
pues nuestras preguntas están relacionadas con el efecto de sexo. Si esas
variables pudieran influír causalmente tanto a sexo como a peso, entonces
deberíamos incluirlas, como veremos más adelante. 
- También sabemos que hay muchas causas comunes de altura y peso. Por ejemplo,
nutrición o medio ambiente. Si esas causas **no** influyen también a sexo, entonces veremos más adelante por qué no es necesario que las incluyamos *para la
pregunta particular que estamos formulando en este ejemplo*.

Dada el diagrama, consideramos un modelo generativo como sigue:

```{r}
mod_peso <- cmdstanr::cmdstan_model("../src/peso_estatura_2.stan")
print(mod_peso)
```

```{r}
datos_lista <- list(N = 500)
ajuste <- mod_peso$sample(data = datos_lista, refresh = 1000, fixed_param = TRUE)
sims <- ajuste$draws(c("s", "h", "w"), format = "df")
resumen <- ajuste$summary(c("h", "w"))
resumen |> select(variable, mean, q5, q95)
```

```{r, fig.width=5, fig.height = 3, warning=FALSE}
ggplot(sims, aes(x = h, y = w, colour = factor(s))) + geom_point() +
  geom_smooth(se = FALSE)
```

::: callout-tip
# Modelos lineales

- En estos ejemplos, estamos usando modelos lineales sin interacciones, 
pero en realidad podríamos incluír no linealidad (en forma de splines o
modelos teóricos) o interacciones, por ejemplo

- En todos los casos, es importante checar los modelos que hemos construido
(ver [flujo bayesiano](https://arxiv.org/abs/2011.01808)).

:::


*Ejercicios*: 

- Construye un modelo quitando la flecha $S\to W$. 
- Construye un modelo donde $H$ y $S$ interactúan para determinar $W$.
- ¿Qué modelos son más simples en términos de parámetros que son necesarios
para definirlos?


## Variables observadas y no observadas

Nótese que en muchos casos, la estructura que genera los datos puede incluir
variables que no hemos medido. No siempre es una buena idea quitar estas variables
porque simplemente nos las conocemos. Dado el proceso generador,
no tendría mucho sentido escribir $S_1 \to S_2$ o $S_2 \to S_1$ (aunque podríamos construir tales modelos).

En este caso, podríamos mejor escribir:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=circle]
    X
  node [shape=plaintext]
    S1 [label = <S<SUB>1</SUB>>]
    S2 [label = <S<SUB>2</SUB>>]
  edge [minlen = 3]
    X -> S1
    X -> S2
{ rank = same; S1; S2 }
}
", width = 200, height = 50)
```



La estructura del modelo junto con la naturaleza de las relaciones que conocemos
nos permitirá hacer inferencia sobre esas variables no observadas, por ejemplo:

```{r}
mod_monedas <- cmdstanr::cmdstan_model("../src/monedas.stan")
print(mod_monedas)
```
```{r}
datos_lista <- list(s_1 = 5, s_2 = 3)
ajuste <- mod_monedas$sample(data = datos_lista, refresh = 1000)
sims <- ajuste$draws(c("x"), format = "df")
resumen <- ajuste$summary(c("x"))
resumen |> select(variable, mean, q5, q95)
```

De modo que con alta probabilidad, escogimos una $X$ entre .5 y 0.93.





### Ejemplo (estudio de Santa Clara)

En 2020 se hizo un estudio de seroprevalencia de COVID en Santa Clara, California.

Se tomó una muestra de individuos (ver los detalles en [el artículo original](https://www.medrxiv.org/content/10.1101/2020.04.14.20062463v2.full.pdf)). Para
propósitos de este análisis supondremos que la muestra puede considerarse como aleatoria simple.

Se obtuvieron 3,300 individuos, y 50 de ellos resultaron con prueba positiva (1.5%). 
Sin embargo,
el kit de prueba que estaban utilizando, tienen cierta especificidad
y sensibilidad menores a 1. En pruebas de *gold standard*, el kit identificó correctamente como positivos a 103 de 122 personas infectadas,
e identificó correctamente como negativos a 399 de 401 personas no infectadas.


Aunque aprender el flujo de construcción y validación de modelos en todos sus aspectos
no es el objetivo de este curso, mostramos un resumen abajo:

:::callout-note
# Desarrollo de modelos

1. Establecer la pregunta que queremos contestar
2. Especificar nuestros supuestos causales
3. Definir un modelo generativo dado el paso anterior
4. Definir una estrategia para contestar la pregunta de 1)
5. Probar el modelo y nuestra estrategia usando el modelo generativo
6. Analizar datos con el modelo, checar supuestos y resumir.
:::


Construiremos ahora una gráfica que indica cómo es el proceso generador de datos.
En primer lugar, no interesa estimar la seropositividad en una población dada,
que suponemos fue muestreada al azar. Nosotros solamente observamos si la prueba
que usamos es positiva o negativa. Escribimos entonces para empezar:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=circle]
    prev
    Inf
  node [shape=plaintext]
    Inf
    Positivos
    N
    
  edge [minlen = 3]
    prev -> Inf
    Inf -> Positivos
    N -> Inf
    
}
", width = 150, height = 60)
```

Nótese que estamos pensando de forma causal al dibujar las aristas:

- $N$ (el tamaño de muestra) es una variable que controlamos. No está determinada
por la prevalencia. La flecha debe ser $prev \to Inf$, pues sabemos que si la prevalencia
es diferente, entonces el número de personas con infección previa tiene una distribución
diferente. Sin embargo, si intervenimos y cambiamos por alguna razón la variable $Inf$, claramente
esto no tiene ningún efecto en $p$ ni en $N$.

- $Inf$ influye en la distribución de positivos, y el número de positivos está determinado solamente por las características de la prueba. Nótese que si sabemos $Inf$, entonces
el número de positivos no influye en en $p$ ni en $N$, y que cambiar la prueba por ejemplo,
no cambia la distribución de la variable $Inf$. De modo que la única flecha que
debemos agregar es $Inf \to Positivos$.

- Aunque podríamos agregar muchos factores que influyen en la prevalencia, estas variables
no afectan directamente a otras variables de nuestro diagrama. Dado que no nos interesa
contestar este tipo de preguntas, omitimos estas variables.

Un camino sería ahora decidir que $Inf=Positivos$, es decir no son releventes las
características de la prueba, y proceder con la inferencia. Sin embargo, la pregunta qué tenemos qué hacer, es ¿puede ser que las características
de la prueba influyan considerablemente en las estimaciones que obtenemos?

Antes de proceder a incluir las características de la prueba, haremos el análisis
pensando que el error de medición no es importante:

```{r}
library(cmdstanr)
mod_sc <- cmdstan_model("../src/sclara-simple.stan")
print(mod_sc)
```



```{r}
n <- 50
N <- 3300
datos_lista <- list(N = 3300, n = 50)
ajuste <- mod_sc$sample(data = datos_lista, refresh = 1000)
sims <- ajuste$draws(c("p"), format = "df")
resumen <- ajuste$summary(c("p"))
```

```{r}

resumen |> select(variable, mean, q5, q95)
```

Y podemos graficar la posterior de la seroprevalencia:

```{r, fig.width = 5, fig.height=3.5}
ggplot(sims, aes(x = p)) + 
  geom_histogram()
```
Donde parece ser que la prevalencia está muy probablemente por arriba de 1.2%
Si este es el caso, esto implicaría que el subconteo de infecciones era muy
grande, y la estimación del IFR podría ser demasiado baja.


Sin embargo, observamos positivos en la prueba, y no realmente
si alguien se ha infectado o no. 
Ahora incluimos sensibilidad y especificidad:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=circle]
    prev
    Inf
    sens
    esp
  node [shape=plaintext]
    Inf
    Positivos
    N

  edge [minlen = 3]
    prev -> Inf
    Inf -> Positivos
    N -> Inf
    sens -> Positivos
    esp -> Positivos
}
", width = 150, height = 60)
```

- Nótese que sens y esp, si las modificamos, no cambian nada de $N$, $Inf$, ni
la prevalencia. Igualmente, las flechas deben ir hacia $Inf$, pues modificar esta
cantidad no produce cambios en las características de la prueba.
- Para entender si tenemos que agregar una flecha de sensibilidad a especificidad
tendríamos que pensar en el proceso que genera estas variables. Podemos
pensar en primer lugar que una variable común que determina estas dos cantidades
es, por ejemplo, la curva ROC de la prueba que produciría una asociación negativa
en estas variables. En un ejercicio más adelante exploraremos esto, pero por el
momento no consideramos esto (por ejemplo, podría ser que existiera una
relación inversa entre especificidad y sensibilidad, que depende de la curva ROC).


Finalmente, tenemos los datos de las pruebas de gold estándar que se hicieron para
las pruebas. Esto incluye cuantos casos verificados positivos/negativos se les aplicó la prueba,
cuántos casos fueron correctamente clasificados por la prueba en cada caso. Dibujamos entonces:


```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=circle]
    sens
    esp
    prev
    Inf
  node [shape=plaintext]
    Inf
    Positivos
    npos
    poskit
    nneg
    negkit
    N
    
  edge [minlen = 3]
    npos -> poskit
    sens -> poskit
    nneg -> negkit
    esp -> negkit
    prev -> Inf
    Inf -> Positivos
    sens -> Positivos
    esp -> Positivos
    N -> Inf
    
}
", width = 150, height = 60)
```

- Las flechas que acabamos de dibujar corresponden a la discusión que tenemos arriba. Por ejemplo, cambiar $esp$ cambia la distribución de el número de negativos que obtuvimos,
pero intervenir en el número de negativos (por ejemplo, escogiendo las personas que se ven sanas para hacerse la prueba y descartar a otro) no tiene efecto sobre $esp$. 

Ahora escribimos los modelos locales siguiendo los supuestos que acabamos de establecer,
que en este caso están determinados:


```{r}
library(cmdstanr)
mod_sc <- cmdstan_model("../src/sclara.stan")
print(mod_sc)
```



```{r}
n <- 50
N <- 3300
datos_lista <- list(N = 3300, n = 50,
 kit_pos = 103, n_kit_pos = 122,
 kit_neg = 399, n_kit_neg = 401)
ajuste <- mod_sc$sample(data = datos_lista, refresh = 1000)
sims <- ajuste$draws(c("p", "sens", "esp"), format = "df")
resumen <- ajuste$summary(c("p"))
```

```{r}

resumen |> select(variable, mean, q5, q95)
```

Y podemos graficar la posterior de la seroprevalencia:

```{r, fig.width = 5, fig.height=3.5}
ggplot(sims, aes(x = p)) + 
  geom_histogram()
```

Y vemos que los datos son consistentes con el dato reportado por los autores (alrededor
de 1.2%), pero que no podemos excluir valores de prevalencia muy bajos (por abajo de 0.3% por ejemplo). Por otro lado, también son consistentes valores muy altos de seroprevalencia, 
de manera que este estudio resultó ser poco informativo de la IFR del COVID.

Podemos hacer diagnósticos adicionales acerca de la razón de esta variabilidad alta,
si graficamos la relación entre especificidad de la prueba y estimación de prevalencia:

```{r, fig.width = 5, fig.height=4}
ggplot(sims, aes(x = esp, y = p)) + geom_point() +
  xlab("Especificidad del kit") + ylab("Prevalencia") + geom_smooth()
```

La asociación entre estas dos cantidades es interesante porque conceptualmente
(y desde punto de vista del modelo), no hay relación entre estas dos variables: su asociación
aparece porque son causas que compiten para explicar una observación.


## Independencia condicional

::: {.callout-note}
# Indepencia condicional

Sean $X,Y,Z$ variables aleatorias. Decimos que $X$ y $Y$ son condicionalmente independientes
cuando satisfacen
$$p(x,y|z) = p(x|z)p(y|z)$$
o equivalentemente,
$$p(x|y,z) = p(x|z)$$
:::

En palabras: si conocemos el valor de $Z$, $X$ y $Y$ ya no están asociadas, o si ya condicionamos
a z, entonces condicionar adicionalmente a $Y$ no cambia la distribución condicional de $X$. Para ver
por qué las dos formas son equivalentes recuerda que cualquier regla de probabilidad general
puede condicionarse a cualquier infromación y sigue siendo una regla válida. Como de mostramos
que $p(x,y) = p(x)p(y)$ si y sólo si $p(y|x) = p(y)$, podemos obtener una regla válida condicionando
todo a $Z$.

En nuestro
primer ejemplo de la sección anterior, observamos que una vez que sabíamos $X$, la probabilidad
de sol, no hay relación entre $X$ y $Y$, aún cuando no es cierto que
$p(x,y) = p(x)p(y)$.

Podemos checar esto en las simulaciones, por ejemplo:

```{r, fig.width=5, fig.height = 3}
set.seed(812)
simular_dos(1e5, x = 0.4) |> 
  select(s_1, s_2) |> 
  group_by(s_1, s_2) |> 
  count() |> 
  group_by(s_1) |> 
  mutate(prop_cond = n / sum(n)) |> 
ggplot(aes(x = s_2, y = prop_cond, colour = s_1, group = factor(s_1))) +
  geom_line()
```
Las condicionales son iguales, de modo que son independientes dado $x = 0.4$.



## Gráficas dirigidas acíclicas

Para representar la construcción de modelos que hemos considerado
de manera gráfica, podemos usar las siguiente idea: 

::: {.callout-note}
Decimos que una gráfica dirigida $G$ **representa** a una conjunta $p(x_1,\ldots, x_p)$
cuando podemos factorizar

$$p(x_1,\ldots, x_p) = \prod_{i=1}^p p(x_i | pa(x_i))$$

donde $pa(x_i)$ son los padres del nodo X_i en la gráfica G.
:::


#### Ejemplo

Consideramos la siguiente gráfica:

```{r}
#| code-fold: true

grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    Ob
    Fuma
    EC 
    Tos
  edge [minlen = 3]
   Ob -> EC
   Fuma -> EC
   Fuma -> Tos
}
", width = 200, height = 50)
```

Esta gráfica representa una conjunta $p(o,f,c,t)$ cuando es posible factorizar

$$p(o,f,c,t) = p(f)p(o)p(c|o,f)p(t|f),$$    
de forma que podemos entender el proceso generador de este conjunto de variables como
sigue: simulamos primero $F$ y $O$, usando el valor de $F$ podemos simular $T$,
y usando el valor de $F$ y $C$ podemos simular $C$. En este ejemplo podemos
pensar que las variables son Obesidad, Fumador, Enfermedad de Corazón y Tos. Nótese
que la distribución de Enfermedad de Corazón depende del estado de Obesidad y fumador.
La probabilidad de tener tos depende directamente del estado de fumador.


El conjunto de independencias condicionales de una conjunta $p$ está fuertemente ligado a la estructura
de la gráfica que la representa:

::: {.callout-note}
Una distribución $p$ es representada por $G$ si y sólo si para cada variable
$W$, cuando condicionamos a los padres $pa(W)$ de $W$, $W$ es
condicionalmente independiente
de todas las variables que no son descendientes o padres de $W$.
:::

Es decir, si condicionamos a los padres de una variable, esta variable es
condicionalmente independiente de "el pasado". Estas no son las únicas independencias
condicionales que están presentes, veremos que para calcular éstas es necesario
usar el concepto de d-separación. Antes discutiremos las estructuras básicas
que nos interesan en una gráfica.

### Independencia condicional, parsimonia y supuestos

La independencia condicional es un concepto central para construir modelos
probabilísticos, pues nos permite construir modelos **parsimoniosos**.

- En una factorización dada, cada factor representa un modelo distinto, que
puede tener parámetros que definen la relación entre la variable resultante y sus
padres.
- Si en nuestro modelo existen independencias condicionales, podemos hacer modelos
con menos parámetros, y cada relación es más simple.

En nuestro ejemplo anterior, si $T$ tuviera más padres en lugar
de tener que definir o estimar $p(t|f)$, tendríamos que modelar
$p(t|o,f,c)$, que es un modelo más complicado: por ejemplo, puede tener interacciones
complicadas y no linealidades más complejas que el modelo $f(t|f)$

Adicionalmente, el conjunto de independencias condicionales también nos dice 
que implicaciones tiene el modelo que estamos considerando. Más adelante veremos
cómo:

- Calcular todas las independencias condicionales dada nuestra gráfica
- Entender en qué lugares puede haber dependencias y explicar la razón de su existencia,
por ejemplo, asi la relación es causal o no.

Por ejemplo, cuando consideramos las dos colecciones de volados ($S_1$ y $S_2$) dada una misma moneda ($X$), podemos entender por qué $S_1$ y $S_2$ **no** son independientes: saber el resultado de $S_1$, por ejemplo, nos da información acerca la $X$, lo cual a su vez 
nos da información de $S_2$. La información fluye a lo largo de la gráfica correspondiente
dado el supuesto que hicimos que las dos series de volados se hacen con una moneda.






## Estructuras básicas en DAGs

Veremos que para razonar acerca de las asociaciones e independencias
que pueden aparecer en una conjunta, podemos examinar la gráfica que la represente, o dicho de otra manera, entender bajo qué condiciones
puede propagarse información de un nodo a otro.

Consideremos entonces tres variables $X$, $Y$ y $Z$. Las tres estructuras
que tenemos que entender en primer lugar pueden verse también como métodos de
razonamiento lógico derivados de las leyes de probabilidad:

### Razonamiento de mediación

En este caso tenemos:

```{r}
#| code-fold: true

grViz("
digraph {
  graph [ranksep = 0.2, rankdir=LR]
  node [shape=plaintext]
    X
    Y
    Z
  edge [minlen = 3]
   X -> Z
   Z -> Y
}
", width = 150, height = 20)
```

En este caso, 

- Existe  asociación entre $X$ y $Y$, pero no existe relación directa entre ellas.
- Si condicionamos a un valor de $Z$, $X$ y $Y$ son condicionalmente independientes.

Podemos pensar en $Z$ como un mediador del efecto de $X$ sobre $Y$. Si no 
permitimos que $Z$ varíe, entonces la información de $X$ no fluye a $Y$.

Por ejemplo, si $X$ tomar o no una medicina para el dolor de cabeza,
$Z$ es dolor de cabeza y $Y$ es bienestar general, $X$ y $Y$ están 
relacionadas. Sin embargo, si condicionamos a un valor fijo de dolor
de cabeza, no hay relación entre tomar la medicina y bienestar general.

En términos de factorización, podemos checar la independencia condicional:
como $p(x,y,z) = p(x)p(z|x)p(y|z)$, entonces

$$p(x, y | z) = p(x,y,z) / p(z) = (p(x)(z|x)) (p(y|z) / p(z))$$
y vemos que el lado izquierdo se factoriza en una parte que sólo involucra a $x$ y $z$
y otro factor que sólo tiene a $y$ y $z$: no hay términos que incluyan conjuntamente a 
$x$, $y$ y $z$. Podemos de cualquier forma continuar notando

$$p(x)p(z|x)/p(z) = p(x,z)/p(z) = p(x | z)$$
de modo que

$$p(x, y | z) = p(x|z) p(y|z) $$

### Razonamiento de causa común

En el siguiente ejemplo, llamamos a $Z$ una causa que es común a $X$ y $Y$.

```{r}
#| code-fold: true

grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    X
    Y
    Z
  edge [minlen = 3]
   Z -> X
   Z -> Y
}
", width = 200, height = 50)
```

En este caso, 

- $X$ y $Y$ tienen asociación
- Si condicionamos a  $Z$, entonces $X$ y $Y$ son condicionalmente
independientes.


Este tipo de estructura también se llama bifurcación, o decimos que $Z$ es un
**confusor** en esta gráfica. Variación en $Z$ produce variación conjunta de $X$ y $Y$.

Por ejemplo,  podríamos encontrar que el uso de aspirina $X$ está asociado
a una mortalidad más alta $Y$. Una causa común es enfermedad grave que produce dolor ($Z$). Sin embargo, si condicionamos a personas sanas, veríamos
que no hay relación entre uso de aspirina y mortalidad, igualmente veríamos
que entre las personas enfermas el uso de aspirina no les ayuda a vivir más tiempo.

En este caso, tenemos:

$$p(x, y, z) =  p(z)p(x|z)p(y|z)$$
Y como el lado izquierdo es igual (en general) a $p(x,y|z)p(z)$, obtenemos
la independiencia condicional de $X$ y $Y$ dado $Z$.

### Razonamiento de causas alternativas o efecto común

En este caso, a $Z$ también le llamamos un **colisionador**. Este es
el caso que puede ser más difícil de entender en un principio.

```{r}
#| code-fold: true

grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    X
    Y
    Z
  edge [minlen = 3]
   X -> Z
   Y -> Z
}
", width = 200, height = 50)
```

- En este caso $X$ y $Y$ son independientes
- Sin embargo, si condicionamos a $Z$ entonces $X$ y $Y$ están asociados.


Por ejemplo, si observamos que el 
pasto está mojado, entonces saber que no llovió implica que probablemente
se encendieron los aspersores.

Como la conjunta se factoriza como:

$$p(x,y,z) = p(x)p(y)p(z|x,y)$$
podemos integrar sobre $Z$:

$$p(x,y) = \int p(x,y,z)dz = p(x)p(y)\int p(z|x,y)\, dz$$
pero $p(z|x,y)$ integra uno porque es una densidad, de forma que $x$ y $y$ son 
independientes.

### Ejemplo

Verificamos que en nuestro modelo de Santa Clara, efectivamente nuestro
modelo no implica ninguna dependencia no condicional entre sensibilidad de la
prueba y prevalencia. Eso debería ser claro de la simulación, pero de
todas formas lo checamos

```{r}
library(cmdstanr)
mod_sc <- cmdstan_model("../src/sclara.stan")
print(mod_sc)
```

En este caso, no pondremos información acerca de positivos en la prueba:

```{r}
datos_lista <- list(N = 0, n = 0,
 kit_pos = 103, n_kit_pos = 122,
 kit_neg = 399, n_kit_neg = 401)
ajuste <- mod_sc$sample(data = datos_lista, refresh = 1000, iter_sampling = 400)
sims <- ajuste$draws(c("p", "sens", "esp"), format = "df")
resumen <- ajuste$summary(c("p"))
```

```{r}
ggplot(sims, aes(x = p, y = sens)) + geom_point() +
  scale_x_sqrt()
```

No vemos ninguna asocación entre estas dos variables. Podemos hacer
algunas permutaciones al azar para checar que nuestra interpetación de la gráfica es 
correcta:

```{r}
library(nullabor)
ggplot(lineup(null_permute("p"), sims, n = 5), aes(x = p, y = sens)) +
  geom_point(alpha = 0.3) + facet_wrap(~ .sample) +
  scale_x_sqrt()
```

Donde no notamos ninguna diferencia sistemática después de hacer permutaciones.

Sin embargo, al condicionar al valor de Positivos, creamos una relación que 
no podemos interpretar como casual. En este caso particular supondremos
prácticamente fija la sensibilidad para ver solamente lo que sucede 
en el colisionador de especificidad y número de positivos (la especificidad
en este ejemplo es más crítica):

```{r}
datos_lista <- list(N = 3300, n = 50,
 kit_pos = 1030000, n_kit_pos = 1220000, # números grandes para que esté practicamente
# fija la sensibilidad
 kit_neg = 399, n_kit_neg = 401)
ajuste <- mod_sc$sample(data = datos_lista, refresh = 1000, iter_sampling = 400)
sims <- ajuste$draws(c("p", "sens", "esp"), format = "df")
resumen <- ajuste$summary(c("p"))
```

```{r}
ggplot(sims, aes(x = p, y = esp)) + geom_point() 
```
Y vemos que condiconando al colisionador, obtenemos una relación fuerte entre prevalencia
y especificidad de la prueba: necesitaríamos más datos de especificidad para
obtener una estimación útil.

- La razón de que la especificidad es más importante en este ejemplo es que
la prevalencia es muy baja al momento del estudio, y los falsos positivos pueden introducir
más error en la estimación
- También repetimos nótese que el análisis correcto de estos datos no se puede
hacer con intervalos separados para cada cantidad, sino que debe examinarse la conjunta
de estos parámetros.

### Razonamiento de descendientes de efecto común

Condicionar a un descendiente de un colisionador también produce dependencias 
condicionales:

```{r}
#| code-fold: true

grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    X
    Y
    Z
    A
  edge [minlen = 3]
   X -> Z
   Y -> Z
   Z -> A
}
", width = 200, height = 50)
```

En este caso,

- $X$ y $Y$ son independientes
- $X$ y $Y$ son  dependientes si condicionamos a $A$.

Dependiendo de la naturaleza de la asociación entre el colisionador $Z$ y su descendiente
$A$, esta dependencia puede ser más fuerte o más débil. 

Por ejemplo, en nuestro ejemplo donde el pasto mojado es un colisionador entre
cuánta agua dieron los aspersores y cuánta lluvia cayó, un descendiente del pasto
mojado es el estado de las plantas del jardín. Aunque los aspersores trabajan independientemente
de la lluvia, si observamos que las plantas se secaron entonces lluvia y aspersores están
correlacionados: por ejemplo, si noto que los aspersores están descompuestos, encontces
concluimos que no hubo lluvia.

```{r}
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    X [label = lluvia]
    Y [label = aspersores]
    Z [label = humedad]
    A [label = plantas]
  edge [minlen = 3]
   X -> Z
   Y -> Z
   Z -> A
}
", width = 200, height = 50)

```


Con estas tres estructuras elementales podemos entender de manera abstracta
la existencia o no de asociaciones entre nodos de cualquier gráfica dirigida.


## d-separación


Ahora buscaremos describir todas las posibles independendencias condicionales
y no condicionales que pueden aparecer en una gráfica, para entender cómo aparecen
asociaciones entre variables de nuestro modelo, y dependiendo del tipo de condicionamiento
que hacemos.

Veremos que el criterio es algorítmico. Más adelante discutiremos cuáles de estas
asociaciones se deben a efectos causales y cuáles no, y esto nos permitirá establecer
estrategias de condicionamiento (qué variables controlar o no), recolección de datos
para construir los estimadores correctos de los efectos causales de interés.


::: callout-note
# Caminos activos y bloqueados

- Un **camino** entre $X$ y $Y$ es una sucesión de aristas que conecta a $X$ con $Y$
(sin importar) la dirección de las aristas.
- Decimos que un camino $p$ entre $X$ y $Y$ está **bloqueado** por un conjunto de nodos
$A$ cuando:
1. El camino $p$ contiene una cadena o una bifurcación tal que el nodo intermedio
está en $A$, o
2. El camino $p$ contiene un nodo colisionador $Z$ tal que el nodo de colisión no está en $A$,
y ningún descendiente de $Z$ está en $A$

Si $A$ bloquea todos los caminos posibles entre $X$ y $Y$, decimos que $X$ y $Y$ están
$d$-**separados** condicionalmente a $Z$.
:::

Cuando un camino entre $X$ y $Y$ no está bloqueado, entonces decimos que está **activo**. Según la discusión que tuvimos arriba de los modos de razonamiento en gráficas de modelos
probabilísticos, el siguiente teorema no es sorpresa:

::: callout-note
# Criterio de d-separación

En una DAG $G$:

- Si dos variables están d-separadas condicional a $Z$, entonces $X$ y $Y$ son condicionalmente independientes para cualquier conjunta representada por $G$.
- Si dos variables **no** están d-separadas condicional a $Z$, entonces existen conjuntas representadas por $G$ tales que $X$ y $Y$ **no** tienen dependencia condicional a $Z$.
:::

**Nota 1**: nótese que este teorema nos da una manera abstracta de razonar acerca
de la asociación en un modelo gráfico: no es necesario saber la forma particular
de las condicionales para utilizarlo.

**Nota 2**: Vale la pena mencionar que el segundo inciso en general es una implicación más fuerte:  cuando no hay $d$-separación, existe algún tipo de dependencia casi seguro (en el sentido probabilístico de posible conjuntas).

Finalmente (ver por ejemplo @koller2009, p 75), existe un algoritmo eficiente para encontrar
todas las posibles independencias condicionales implicadas por una gráfica:

::: callout-note
# Cálculo de d-separación

Existe un algoritmo de complejidad lineal en el tamaño de la gráfica para encontrar 
todos los nodos con caminos activos a un nodo $X$ condicional a las variables $A$.
:::

### Ejemplo {-}

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    Z 
    W 
    X
    Y 
    U
  edge [minlen = 3]
    Z -> W
    X -> W
    X -> Y
    W -> U
    S -> Y
    UZ -> Z
}
")
```

Consideremos la relación entre Z y Y.

- En primer lugar, ¿son independientes? Sí, pues el único camino entre $Z$ y $Y$ está 
bloqueado por $W$, que es un colisionador.
- Si condicionamos a $W$, ¿son independientes? No, pues activamos el único camino al
condicionar a un colisiionador.
- Si condicionamos a $W$, ¿son independientes? No, pues activamos el único camino al
condicionar a el descendiente de un colisionador.
- Sin embargo, si por alguna razón tenemos datos condicionales a $W$, condicionando adicionalmente a $X$ (es decir, condicionando al conjunto $\{W, X\}$), notamos
que ahora hemos bloqueado el camino que condicionar al colisionador había abierto.
Por lo tanto, $X$ y $Y$ son condicionalmente independientes dadas  $\{W, X\}$

### Ejercicio

Repite el ejemplo anterior para la siguiente gráfica. 
Analiza que pasa si condicionamos o no a valores de $T$, y qué pasa si adicionalmente
condicionamos a $W$, y luego repite los pasos del ejemplo anterior.

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    Z 
    W 
    X
    Y 
    U
    T
  edge [minlen = 3]
    T -> Z
    T -> Y
    Z -> W
    X -> W
    X -> Y
    W -> U
    S -> Y
    UZ -> Z
}
")

```


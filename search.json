[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos analíticos",
    "section": "",
    "text": "Temario y referencias\nTodas las notas y material del curso estarán en este repositorio.\n\nParte 1: Inferencia causal\n\nIntroducción a inferencia causal\nModelos probabilísticos gráficos\nEstimación de efectos causales\nExperimentos y controles\nContrafactuales de Rubin\nOtros métodos de inferencia causal\n\nParte 2: Análisis de series de tiempo y pronósticos\n\nDescomposición de series de tiempo\nIngeniería de entradas para datos de series de tiempo\nMétodos clásicos para pronósticos\nModelo de espacio de estados\nInferencia causal para series de tiempo\n\n\n\nEvaluación\n\nTareas semanales (20%)\nExamen parcial (40% teórico)\nUn examen final (40% práctico)\n\n\n\nMaterial\nCada semestre las notas cambian, en algunas partes considerablemente. Las de este semestre están en este repositorio, incluyendo ejemplos, ejercicios y tareas.\n\n\nReferencias principales\n\nParte 1\n\nStatistical Rethinking\nCausal Inference in Statistics: a primer\nCounterfactuals and Causal Inference: Methods and Principles for Social Research\n\nParte 2:\n\nForecasting: Principles and Practice\nTime Series Analysis by State Space Methods\n\n\n\n\nOtras referencias\n\nPattern Recognition and Machine Learning, Bishop (2006)\nThe Book of Why\nData Analysis Using Regression and Multilevel/Hierarchical Models\nAn Introduction to State Space Time Series Analysis ### Software: R y Rstudio {-}\n\nPara hacer las tareas y exámenes pueden usar cualquier lenguaje o flujo de trabajo que les convenga (R o Python, por ejemplo) - el único requisito esté basado en código y no point-and-click.\n\n\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning (Information Science and Statistics). Secaucus, NJ, USA: Springer-Verlag New York, Inc."
  },
  {
    "objectID": "01-introduccion.html#qué-es-inferencia-causal",
    "href": "01-introduccion.html#qué-es-inferencia-causal",
    "title": "1  Introducción (Parte 1)",
    "section": "1.1 ¿Qué es inferencia causal?",
    "text": "1.1 ¿Qué es inferencia causal?\nLa inferencia causal consiste en predecir los posibles efectos de intervenciones, y entender qué pasaría si las condiciones que observamos fueran diferentes, es decir, condiciones contrafactuales. Tanto en ciencia como en industria, estos dos conceptos son muy importantes:\nIntervenciones (acciones):\n\n¿Qué efecto tiene sobre las ventas reducir el presupuesto de publicidad?\n¿Qué efecto tienen sobre la salud de una persona administrarle un medicamento?\n¿Cuáles son las expectativas de un hogar que ponemos en un programa gubernamental relacionado con la educación o la salud?\n\nContrafactuales (no necesariamente intervenciones que podemos controlar o ejecutar, sino escenarios hipotéticos):\n\n¿Cuánto ha contribuido a las ventas de un producto el gasto en publicidad?\n¿Cuál sería el ingreso de una persona si tuviera un año más de estudios?\n¿Cómo sería la salud de una persona que ha fumado durante 10 años si no hubiera fumado?\n\nEste tipo de preguntas centrales en la industria y la ciencia generalmente no pueden contestarse únicamente usando términos estadísticos y datos disponibles. Las razones son:\n\nAsociaciones entre variables observadas no implican relaciones causales entre las variables.\nLa ausencia de asociación entre variables observadas no implica que no hay relación causal entre ellas.\nRelaciones causales no están en los datos: están en el conocimiento experto o teoría científica.\n\nLa evaluación de intervenciones y de contrafactuales tienen una lógica similar, pero su naturaleza conceptual es diferente: en un caso"
  },
  {
    "objectID": "01-introduccion.html#preguntas-y-datos",
    "href": "01-introduccion.html#preguntas-y-datos",
    "title": "1  Introducción (Parte 1)",
    "section": "1.2 Preguntas y datos",
    "text": "1.2 Preguntas y datos\nPara entender y poder usar datos para contestar preguntas de interés, el paso inicial más importante es entender bajo que proceso se generan los datos. Veremos cómo estos procesos generadores se expresan en términos causales.\n\nCuanto más sepamos de este proceso, mejor podemos contestar preguntas de interés\nEn muchos casos, tenemos qué hacer supuestos basados en conocimiento experto acerca de este proceso generador para poder producir (o no) respuestas.\n\nEn particular, en inferencia causal:\n\nSi no tenemos los supuestos y hechos relevantes que definen el proceso generador de datos, no es posible dar respuestas a preguntas causales\n\n\nEjemplo (cálculos renales)\nEste es un estudio real acerca de tratamientos para cálculos renales (Julious y Mullee (1994)). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.\nLa tabla original tiene 700 renglones (cada renglón es un paciente)\n\ncalculos <- read_csv(\"../datos/kidney_stone_data.csv\")\nnames(calculos) <- c(\"tratamiento\", \"tamaño\", \"éxito\")\ncalculos <- calculos |> \n   mutate(tamaño = ifelse(tamaño == \"large\", \"grandes\", \"chicos\")) |> \n   mutate(resultado = ifelse(éxito == 1, \"mejora\", \"sin_mejora\")) |> \n   select(tratamiento, tamaño, resultado)\nnrow(calculos)\n\n[1] 700\n\n\ny se ve como sigue (muestreamos algunos renglones):\n\ncalculos |> \n   sample_n(10) |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    resultado \n  \n \n\n  \n    A \n    chicos \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    grandes \n    mejora \n  \n  \n    A \n    grandes \n    sin_mejora \n  \n  \n    A \n    grandes \n    sin_mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    grandes \n    mejora \n  \n  \n    B \n    grandes \n    mejora \n  \n\n\n\n\n\nAunque estos datos contienen información de 700 pacientes, los datos pueden resumirse sin pérdida de información contando como sigue:\n\ncalculos_agregada <- calculos |> \n   group_by(tratamiento, tamaño, resultado) |> \n   count()\ncalculos_agregada |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    resultado \n    n \n  \n \n\n  \n    A \n    chicos \n    mejora \n    81 \n  \n  \n    A \n    chicos \n    sin_mejora \n    6 \n  \n  \n    A \n    grandes \n    mejora \n    192 \n  \n  \n    A \n    grandes \n    sin_mejora \n    71 \n  \n  \n    B \n    chicos \n    mejora \n    234 \n  \n  \n    B \n    chicos \n    sin_mejora \n    36 \n  \n  \n    B \n    grandes \n    mejora \n    55 \n  \n  \n    B \n    grandes \n    sin_mejora \n    25 \n  \n\n\n\n\n\nComo en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:\n\ncalculos_agregada |> pivot_wider(names_from = resultado, values_from = n) |> \n   mutate(total = mejora + sin_mejora) |> \n   mutate(prop_mejora = round(mejora / total, 2)) |> \n   select(tratamiento, tamaño, total, prop_mejora) |> \n   arrange(tamaño) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    total \n    prop_mejora \n  \n \n\n  \n    A \n    chicos \n    87 \n    0.93 \n  \n  \n    B \n    chicos \n    270 \n    0.87 \n  \n  \n    A \n    grandes \n    263 \n    0.73 \n  \n  \n    B \n    grandes \n    80 \n    0.69 \n  \n\n\n\n\n\nEsta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Pero es apropiada para empezar a contestar la pregunta:\n\n¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?\n\nSupongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:\n\ncalculos |> group_by(tratamiento) |> \n   summarise(prop_mejora = mean(resultado == \"mejora\") |> round(2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    prop_mejora \n  \n \n\n  \n    A \n    0.78 \n  \n  \n    B \n    0.83 \n  \n\n\n\n\n\ny parece ser que el tratamiento \\(B\\) es mejor que el \\(A\\). Esta es una paradoja (un ejemplo de la paradoja de Simpson) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar \\(B\\)? ¿Si sabe debería recetar \\(A\\)? Esta discusión parece no tener mucho sentido.\nPodemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:\n\ncalculos |> group_by(tratamiento, tamaño) |> count() |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    n \n  \n \n\n  \n    A \n    chicos \n    87 \n  \n  \n    A \n    grandes \n    263 \n  \n  \n    B \n    chicos \n    270 \n  \n  \n    B \n    grandes \n    80 \n  \n\n\n\n\n\nNuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos. En este caso, hay una decisión pues A es una cirugía y B es un procedimiento menos invasivo, y se prefiere utilizar el tratamiento \\(A\\) para cálculos grandes, y \\(B\\) para cálculos chicos. Esto quiere decir que en la tabla total el tratamiento \\(A\\) está en desventaja porque se usa en casos más difíciles, pero el tratamiento \\(A\\) parece ser en general mejor. La razón es probablemente un proceso de optimización de recursos y riesgo que hacen los doctores.\n\nUna mejor respuesta a la pregunta de qué tratamiento es mejor es la que presenta los datos desagregados\nLa tabla desagregada de asignación del tratamiento nos informa acerca de cómo se está distribuyendo el tratamiento en los pacientes.\n\n\n\n\n\n\n\nNota\n\n\n\nLos resúmenes descriptivos acompañados de hipótesis causales acerca del proceso generador de datos, nos guía hacia descripciones interpretables de los datos.\n\n\nLas explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos.\nPodemos codificar la información causal con un diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    T \n    M \n    C\n  edge [minlen = 3]\n    T -> M\n    C -> T\n    C -> M\n{ rank = same; M; T }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEs decir, el tamaño de los cálculos es una causa común de tratamiento (T) y resultado (M). Veremos más adelante que la decisión de condicionar a el tipo de cálculos proviene de un análisis relativamente simple de este diagrama causal, independientemente de los métodos que usemos para estimar las proporciones de interés (en este ejemplo, examinar las tablas cruzadas es equivalente a hacer estimaciones de máxima verosimlitud).\n\n\nEjemplo (cálculos renales 2)\nContrastemos el ejemplo anterior usando exactamente la misma tabla de datos, pero con el supuesto de un proceso generador diferente. En este caso, los tratamientos son para mejorar alguna enfermedad del corazón. Sabemos que parte del efecto de este tratamiento ocurre gracias a una baja en presión arterial de los pacientes, así que después de administrar el tratamiento, se toma la presión arterial de los pacientes. Ahora tenemos la tabla agregada y desagregada como sigue:\n\ncorazon <- calculos |> \n  select(tratamiento, presión = tamaño, resultado) |> \n  mutate(presión = ifelse(presión == \"grandes\", \"alta\", \"baja\"))\ncorazon_agregada <- corazon |> \n   group_by(tratamiento, presión, resultado) |> \n   count()\ncorazon_agregada |> pivot_wider(names_from = resultado, values_from = n) |> \n   mutate(total = mejora + sin_mejora) |> \n   mutate(prop_mejora = round(mejora / total, 2)) |> \n   select(tratamiento, presión, total, prop_mejora) |> \n   arrange(presión) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    presión \n    total \n    prop_mejora \n  \n \n\n  \n    A \n    alta \n    263 \n    0.73 \n  \n  \n    B \n    alta \n    80 \n    0.69 \n  \n  \n    A \n    baja \n    87 \n    0.93 \n  \n  \n    B \n    baja \n    270 \n    0.87 \n  \n\n\n\n\n\n\ncorazon |> group_by(tratamiento) |> \n   summarise(prop_mejora = mean(resultado == \"mejora\") |> round(2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    prop_mejora \n  \n \n\n  \n    A \n    0.78 \n  \n  \n    B \n    0.83 \n  \n\n\n\n\n\n¿Cuál creemos que es el mejor tratamiento en este caso? ¿Deberíamos usar la tabla agregada o la desagregada por presión?\n\nEn este caso, la tabla agregada es más apropiada (B es mejor tratamiento).\nLa razón es que presión en este caso es una consecuencia de tomar el tratamiento, y como las tablas muestran, B es más exitoso en bajar la presión de los pacientes.\nSi sólo comparamos dentro de los grupos de presión baja o de presión alta, ignoramos lo más importante del tratamiento en la probabilidad de mejorar.\n\nNuestros supuestos causales podemos mostrarlos con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    P\n    T \n    M \n  edge [minlen = 3]\n    T -> P\n    P -> M\n    T -> M\n{ rank = same; M; T}\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\n\n\nEjemplo (admisiones de Berkeley)\nUna ejemplo al que regresaremos más adelante es el siguiente: en 1973 se recolectaron datos agregados de solicitantes para estudiar en Berkeley para los 6 departamentos más grandes, clasificados por sexo del solicitante y si fue admitido o no. Los resultados se muestran a continuación:\n\ndata(\"UCBAdmissions\")\nadm_original <- UCBAdmissions |> as_tibble() |> \n   pivot_wider(names_from = Admit, values_from = n) \nadm_original |> knitr::kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Gender \n    Dept \n    Admitted \n    Rejected \n  \n \n\n  \n    Male \n    A \n    512 \n    313 \n  \n  \n    Female \n    A \n    89 \n    19 \n  \n  \n    Male \n    B \n    353 \n    207 \n  \n  \n    Female \n    B \n    17 \n    8 \n  \n  \n    Male \n    C \n    120 \n    205 \n  \n  \n    Female \n    C \n    202 \n    391 \n  \n  \n    Male \n    D \n    138 \n    279 \n  \n  \n    Female \n    D \n    131 \n    244 \n  \n  \n    Male \n    E \n    53 \n    138 \n  \n  \n    Female \n    E \n    94 \n    299 \n  \n  \n    Male \n    F \n    22 \n    351 \n  \n  \n    Female \n    F \n    24 \n    317 \n  \n\n\n\n\n\ny las proporciones de admisión por sexo y departamente son las siguientes:\n\nadm_tbl <- adm_original |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected), 2), total = Admitted + Rejected) |> \n   select(Gender, Dept, prop_adm, total) |> \n   pivot_wider(names_from = Gender, values_from = prop_adm:total)\nadm_tbl |> knitr::kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Dept \n    prop_adm_Male \n    prop_adm_Female \n    total_Male \n    total_Female \n  \n \n\n  \n    A \n    0.62 \n    0.82 \n    825 \n    108 \n  \n  \n    B \n    0.63 \n    0.68 \n    560 \n    25 \n  \n  \n    C \n    0.37 \n    0.34 \n    325 \n    593 \n  \n  \n    D \n    0.33 \n    0.35 \n    417 \n    375 \n  \n  \n    E \n    0.28 \n    0.24 \n    191 \n    393 \n  \n  \n    F \n    0.06 \n    0.07 \n    373 \n    341 \n  \n\n\n\n\n\nComplementamos con las tasas de aceptación a total por género, y tasas de aceptación por departamento:\n\nadm_original |> group_by(Gender) |> \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Gender \n    Admitted \n    Rejected \n    prop_adm \n  \n \n\n  \n    Female \n    557 \n    1278 \n    0.30 \n  \n  \n    Male \n    1198 \n    1493 \n    0.45 \n  \n\n\n\n\n\nLa pregunta que queremos hacer es: ¿existe discriminación por sexo en la selección de candidatos? Examinando las tablas no está clara cuál es la respuesta.\n\nadm_original |> group_by(Dept) |> \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Dept \n    Admitted \n    Rejected \n    prop_adm \n  \n \n\n  \n    A \n    601 \n    332 \n    0.64 \n  \n  \n    B \n    370 \n    215 \n    0.63 \n  \n  \n    C \n    322 \n    596 \n    0.35 \n  \n  \n    D \n    269 \n    523 \n    0.34 \n  \n  \n    E \n    147 \n    437 \n    0.25 \n  \n  \n    F \n    46 \n    668 \n    0.06 \n  \n\n\n\n\n\nDiscutiremos este ejemplo con más detalle más adelante. La interpretación debe ser hecha con cuidado, y debemos establecer claramente los supuestos que fundamentan nuestra decisión de mostrar cada tabla y de qué forma mostrarlas."
  },
  {
    "objectID": "01-introduccion.html#resumen-de-ejemplos",
    "href": "01-introduccion.html#resumen-de-ejemplos",
    "title": "1  Introducción (Parte 1)",
    "section": "1.3 Resumen de ejemplos",
    "text": "1.3 Resumen de ejemplos\nNótese que en los dos casos anteriores, los datos son exactamente los mismos, pero la respuesta correcta es diferente en cada caso. En la tabla de datos no está la respuesta acerca de qué resumen es el correcto. Solamente conocimiento externo de cómo se generan los datos sugieren cómo debemos tratar y explicar lo que observamos en cada caso.\nA se conocimiento externo es una combinación de\n\nConocimiento de dominio o teorías científicas, y\nEntendimiento de cómo fueron recolectados y procesados los datos, lo cual también es información causal.\n\nEstos ejemplos también muestran adicionalmente que:\n\nIncluso desde un punto de vista puramente descriptivo, es necesario entender algo de la estructura causal del problema para poder dar descripciones interpretables\nSi no tenemos la información correcta, es difíl producir estimaciones causales.\n\nEn el primer ejemplo de cálculos renales fue importante saber saber el hecho de que los doctores seleccionaban el tratamiento según la severidad y que tuviéramos una medición de esa variable. En el segundo ejemplo de presión no era necesaria esa medición adicional.\n\nMás adelante hablaremos de experimentación. Veremos que aquí también entender el proceso generador de datos es importante. Por ejemplo, ¿qué variables podemos usar cómo controles para mejorar la estimación y qué variables no?\nModelos causales nos ayudan a diseñar estudios (experimentales o no) y a decidir qué datos es necesario recolectar."
  },
  {
    "objectID": "01-introduccion.html#más-de-asociación-no-causal",
    "href": "01-introduccion.html#más-de-asociación-no-causal",
    "title": "1  Introducción (Parte 1)",
    "section": "1.4 Más de asociación no causal",
    "text": "1.4 Más de asociación no causal\nDiscutiremos otro ejemplo de los puntos mencionados arriba.\nAlgunos estudios fueron publicados en la primera mitad de 2020 que notaban que el porcentaje fumadores entre los casos positivos de COVID era menor que en la población general, y se hicieron algunas interpretaciones acerca de este hecho. Estos estudios se hicieron con personas que se hicieron una prueba.\nEn este ejemplo replicaremos cómo es que podemos encontrar esta asociación en este tipo de estudios aún cuando no exista tal asociación en la población general (ver este artículo). Usaremos datos sintéticos (simulados).\nPrimero vamos a razonar acerca del proceso generador de datos y a hacer algunos supuestos:\n\nEn primer lugar, ¿cuándo decide hacerse alguien una prueba? A principios de 2020, son principalmente personas que tienen síntomas considerables, y trabajadores de salud (tengan o no síntomas).\nSer trabajador de salud incrementa el riesgo de contagiarse.\nEn algunos países, fumar está asociado con ser trabajador de salud (no tienen la misma tasa de tabaquismo que la población general).\nSólo observamos a las personas que se hicieron una prueba.\nFumar no tiene efectos causales en este modelo.\nIngoramos por el momento que la relación entre covid y prueba positiva no es perfecta.\n\nPodemos resumir cualitativamente con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Prueba\n    TrabSalud\n    Síntomas\n    Fumar\n    Covid\n  edge [minlen = 3]\n    #TrabSalud -> Covid\n    TrabSalud -> Prueba\n    TrabSalud -> Fumar\n    TrabSalud -> Covid\n    U -> Síntomas\n    Covid -> Síntomas\n    Síntomas -> Prueba\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nEl código para simular es el siguiente: todas las variables toman valores 0 o 1, pero con diferentes probabilidades y dependiendo de las variables que son padres en la gráfica de arriba.\n\nSimulamos un millón de personas de las cuales aproximadamente el 1% son trabajadores de salud.\nSuponemos que la probabilidad es de 5% de que un trabajador de salud resulte positivo y de 1% para el del resto de las personas.\nSuponemos que de las personas que tienen covid, el 50% tienen síntomas y de las personas que no tienen covid, el 1% tiene síntomas.\nSuponemos que de los trabadores de salud el 99% se hicieron prueba (sin importar si tenían o no síntomas) y el resto de las personas se divide en 2, de los no trabadores de salud con síntomas, el 85% se hicieron una prueba y de los no trabajdores de salud sin síntomas, el 1% se hizo una prueba\nDe los trabajadores de salud, el 20% fuman, del resto de las personas el 7% fuman.\n\n\n\nCódigo\nset.seed(8221)\n#simular población\nn <- 1e6\ntrab_salud <- rbinom(n, 1, 0.01)\ncovid <- rbinom(n, 1, ifelse(trab_salud==1, 0.05, 0.01))\ndatos <- tibble(trab_salud = trab_salud, covid) |> \n  mutate(sintomas = rbernoulli(n, ifelse(covid == 1, 0.5, 0.01))) |> \n  mutate(prueba = rbernoulli(n, ifelse(trab_salud ==1, 0.99, 0.84 * sintomas + 0.01))) |> \n  mutate(fumar = rbernoulli(n, ifelse(trab_salud == 1, 0.20, 0.07))) |> \n  mutate(covid = ifelse(covid ==1, \"positivo\", \"negativo\")) |> \n  mutate(fumar = ifelse(fumar, \"fuma\", \"no_fuma\"))\n\n\nSuponemos ahora que tomamos como muestra a todas aquellas personas que se hicieron una prueba. En primer lugar, la proporción de fumadores en la muestra es un poco más alta que la población, porque los trabajadores de salud están sobrerrepresentados:\n\ndatos_pruebas <- filter(datos, prueba == 1)\ntable(datos_pruebas$fumar) |> prop.table() |> round(2)\n\n\n   fuma no_fuma \n   0.11    0.89 \n\n\nY ahora vemos que bajo esta condición o filtro, están asociados fumar y tener covid:\n\ntable(datos_pruebas$covid, datos_pruebas$fumar) |> prop.table(margin = 2) |> \n  round(2) \n\n          \n           fuma no_fuma\n  negativo 0.90    0.85\n  positivo 0.10    0.15\n\n\nSin embargo, en la población (sin filtrar por los que se hicieron prueba) en general, esperaríamos una asociación positiva pero relativamente chica de fumar con tener covid (veremos por qué sabemos esto al consultar el diagrama):\n\ntable(datos$covid, datos$fumar) |> prop.table(margin = 2) |> \n  round(4)\n\n          \n             fuma no_fuma\n  negativo 0.9892  0.9896\n  positivo 0.0108  0.0104\n\n\nEsta tampoco es una relación causal. Discutiremos con detalle más adelante por qué condicionar a sólo los que hicieron una prueba produce una correlación fuerte entre estas dos variables que no están causalmente relacionadas.\n\n\n\n\nJulious, Steven A, y Mark A Mullee. 1994. «Confounding and Simpson’s paradox». BMJ 309 (6967): 1480-81. https://doi.org/10.1136/bmj.309.6967.1480."
  },
  {
    "objectID": "02-modelos-graficos.html#repaso-de-probabilidad",
    "href": "02-modelos-graficos.html#repaso-de-probabilidad",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.1 Repaso de probabilidad",
    "text": "2.1 Repaso de probabilidad\nSi \\(X\\) es una variable aleatoria, abusaremos de la notación escribiendo \\(p(x)\\) para denotar su función de densidad (continua o discreta). Si \\(X\\) es discreta, \\(p(x)=P(X=x)\\), y si \\(X\\) es continua, entonces \\(p(x)\\) es la función de densidad, que utilizamos para calcular probabilidades usando integrales, por ejemplo\n\\[P(X \\in [a,b]) = \\int_a^b p(x)\\, dx\\] Ojo: en algunos casos, para evitar reescribir fórmulas, usaremos esta misma notación para denotar probabilidades de variables discretas, que más apropiadamente escribiríamos como \\(P(X\\in[a,b]) = \\sum_{x=a}^{b} P(X = x)\\).\nSi \\(X\\) y \\(Y\\) son variables aleatorias, entonces denotamos por \\(p(x,y)\\) a su densidad conjunta. Podemos calcular las distribuciones de x y y integrando sobre una de las variables\n\\[p(y) = \\int_{-\\infty}^{\\infty} p(x,y)dx = \\int p(x,y)dx\\] Nótese que abusamos algo de la notación quitando los límites de la integral de la derecha (y recordamos que si \\(X\\) es discreta, entonces usamos una suma en lugar de una integral). En este contexto, \\(p(x), p(y)\\) se llaman distribuciones marginales de \\(X\\) y \\(Y\\)\nDenotamos por \\(p(y|x)\\) y \\(p(x|y)\\) a las densidades condicionales de Y dado X y X dada Y respectivamente. Estas están definidas por\n\\[p(y|x) = \\frac{p(x, y)}{p(x)}\\] Esta densidad condicional nos dice cómo se distribuye \\(Y\\) cuando sabemos que \\(X=x\\).\nDe esta definición, tenemos la regla del producto que establece que\n\\[p(x,y) = p(y|x) p(x) = p(x|y)p(y) \\]\nCuando la distribución condicional de \\(p(y|x)\\) cambia dependiendo de la \\(x\\), decimos que \\(X\\) y \\(Y\\) está asociadas. Si no es el caso, decimos que son independientes. Esto quiere decir que\n\\[p(y|x) = p(y)\\] es decir, la condicional de \\(Y\\) dada \\(X\\) es igual a la marginal de \\(Y\\). Por definición, la independencia también se puede escribir como una versión simplificada de la regla del producto:\n\\[p(x,y) = p(x)p(y)\\] es decir, la conjunta se factoriza en una parte que sólo depende de \\(x\\) y otra que sólo dependen de \\(y\\).\n\n\n\n\n\n\nTip\n\n\n\nUna manera útil de construir modelos de probabilidad conjuntas con variables que tienen dependencias es utilizando una factorización de la regla del producto, lo cual nos permite concentrarnos en una variable a la vez.\n\n\nDependiendo del tipo de problema, puede ser más conveniente definir \\(p(x)\\) y \\(p(y|x)\\) o \\(p(y)\\) y \\(p(x|y)\\). En ambos casos podemos calcular la conjunta \\(p(x,y)\\) con la que podemos calcular cualquier probabilidad conjunta de interés o cantidad resumen que involucra a a estas dos variables aleatorias.\n\nEjemplo 1\nSupongamos que \\(X\\) es el resultado de una tirada de dado, y que \\(Y\\) es el número de soles que obtenemos en \\(X\\) volados de una moneda justa.\nEntonces podemos escribir \\(p(x) = 1/6\\) para \\(x=1,2,\\ldots, 6\\), es decir, \\(X\\) es Uniforme en \\(\\{1,2,3,4,5,6\\}\\), y \\(Y|X=x\\) son el número de soles en \\(x\\) volados, de modo que es Binomial con parámetros \\((x, 0.5)\\). Esto lo podemos escribir como\n\\[\\begin{equation}\n\\begin{split}\nY|X \\sim & Bin(X, 0.5) \\\\\nX  = & U(\\{1,2,3,4,5,6\\})\n\\end{split}\n\\end{equation}\\]\nEstas variables no son independientes, pues la condicional de \\(Y\\) cambia dependiendo del valor que toma \\(X\\).\nComo estas dos variables son discretas, la conjunta puede escribirse con la regla del producto como una tabla como sigue:\n\nprobs_x <- tibble(x = 1:6, p_x = 1/6)\nprobs_conjunta <-  crossing(probs_x, y = seq(0, 6, 1)) |> \n  mutate(p_cond_y = dbinom(y, size = x, prob = 0.5)) |> \n  mutate(p = p_cond_y * p_x) #producto\nprobs_conjunta |> select(x, y, p) |> \n  pivot_wider(names_from = x, values_from = p, names_prefix = \"x=\") |> \n  kable(digits = 4) |> kable_paper()\n\n\n\n \n  \n    y \n    x=1 \n    x=2 \n    x=3 \n    x=4 \n    x=5 \n    x=6 \n  \n \n\n  \n    0 \n    0.0833 \n    0.0417 \n    0.0208 \n    0.0104 \n    0.0052 \n    0.0026 \n  \n  \n    1 \n    0.0833 \n    0.0833 \n    0.0625 \n    0.0417 \n    0.0260 \n    0.0156 \n  \n  \n    2 \n    0.0000 \n    0.0417 \n    0.0625 \n    0.0625 \n    0.0521 \n    0.0391 \n  \n  \n    3 \n    0.0000 \n    0.0000 \n    0.0208 \n    0.0417 \n    0.0521 \n    0.0521 \n  \n  \n    4 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0104 \n    0.0260 \n    0.0391 \n  \n  \n    5 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0052 \n    0.0156 \n  \n  \n    6 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0026 \n  \n\n\n\n\n\nNótese adicionalmente que la forma en que planteamos el problema naturalmente nos da un modelo generativo, es decir, podemos simular fácilmente realizaciones de esta conjunta particular:\n\nsimular_juego <- function(n = 1, x = NULL){\n  if(is.null(x)){\n    x <- sample(1:6, n, replace = TRUE)\n  }\n  y <- rbinom(n, x, prob = 0.5)\n  tibble(n = seq_len(n), x = x, y = y)\n}\nset.seed(880)\nsimular_juego(n = 5)\n\n# A tibble: 5 × 3\n      n     x     y\n  <int> <int> <int>\n1     1     5     3\n2     2     5     1\n3     3     3     1\n4     4     6     4\n5     5     4     3\n\n\nY usando simulación podemos estimar cualquier cantidad de interés acerca de las variables \\(X\\) y \\(Y\\). Por ejemplo, su correlación la estimamos con\n\nsimular_juego(n = 10000) |> select(x, y) |> cor()\n\n          x         y\nx 1.0000000 0.6716973\ny 0.6716973 1.0000000\n\n\n\n\nEjemplo 2\nSupongamos que \\(W\\) es una el peso de una persona y \\(H\\) su estatura. Podemos comenzar con la factorización \\(p(w,h) = p(h)p(w|h)\\). Un modelo generativo podría ser el que sigue: \\(H\\) es Normal con media 165 y desviación estandar 12,\n\\[H \\sim N(170, 12) \\]\ny dada la estatura \\(H=h\\), el peso es\n\\[W|H=h \\sim N(m_h, 10)\\] donde\n\\[m_h = -50 + 0.7 h\\]\n\nsim_wh <- function(n = 10){\n  h <- rnorm(n, 170, 12)\n  m_h <- -50 + 0.7 * h\n  w <- rnorm(n, m_h, 10)\n  tibble(w = w, h = h)\n}\n\n\nset.seed(992)\nsims <- sim_wh(500)\nggplot(sims, aes(x = h, y = w)) + geom_point()\n\n\n\n\nTambién escribimos este modelo en stan:\n\nmod_peso <- cmdstanr::cmdstan_model(\"../src/peso_estatura.stan\")\nprint(mod_peso)\n\ndata {\n  int<lower=0> N;\n}\n\nparameters {\n}\n\ntransformed parameters {\n}\n\nmodel {\n\n}\ngenerated quantities {\n  real<lower=0> h;\n  real<lower=0> w;\n\n    h = normal_rng(170, 12);\n    real m_w = -50 + 0.7 * h;\n    w = normal_rng(m_w, 10);\n}\n\n\n\ndatos_lista <- list(N = 500)\najuste <- mod_peso$sample(data = datos_lista, refresh = 1000, fixed_param = TRUE)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 2 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 3 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 4 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\nsims <- ajuste$draws(c(\"h\", \"w\"), format = \"df\")\nresumen <- ajuste$summary(c(\"h\", \"w\"))\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 2 × 4\n  variable  mean    q5   q95\n  <chr>    <dbl> <dbl> <dbl>\n1 h        170.  151.  189. \n2 w         69.0  47.4  90.5\n\n\n\nggplot(sims, aes(x = h, y = w)) + geom_point()"
  },
  {
    "objectID": "02-modelos-graficos.html#caso-multivariado",
    "href": "02-modelos-graficos.html#caso-multivariado",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.2 Caso multivariado",
    "text": "2.2 Caso multivariado\nSupongamos que tenemos \\(X_1,\\ldots, X_p\\) variables aleatorias. Denotamos su conjunta con \\[p(x_1, x_2, \\ldots, x_n)\\] En el caso particular de 3 variables p(x,y,z) la regla del producto se escribe como\n\\[p(x,y,z) = p(z|x,y)p(y|x)p(x)\\] que podemos escribir, dependiendo del problema, en cualquiera de las seis permutaciones posibles, por ejemplo:\n\\[p(x,y,z) = p(x|y,z)p(y|z)p(z)\\]\nEl proceso de simulación lo podemos mostrar gráficamente como sigue:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X \n    Y \n    Z\n  edge [minlen = 3]\n    Z -> Y\n    Y -> X\n    Z -> X\n{ rank = same; Z; Y }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nNótese que este ejemplo puede aplicarse a cualquier conjunta nos interese, pues la factorización resulta de la regla del producto.\n\n2.2.1 Ejemplo\nSupongamos que escogemos al azar un número \\(X\\) entre 0 y 1, y luego tiramos dos veces cinco volados con probabilidad de sol \\(X\\). Medimos el número de soles en cada prueba como \\(S_1\\) y \\(S_2\\).\nEn este caso, es natural escribir la factorización:\n\\[p(x,s_1,x_2) = p(s_2|s_1,x)p(s_1|x)p(x).\\] Sin embargo, podemos simplificar aún más esta conjunta, pues en realidad una vez que sabemos X, el resultado de \\(S_1\\) no cambia la distribución de \\(S_2\\), de forma que para el proceso que describimos arriba,\n\\[p(x, s_1, s_2) = p(s_2|x)p(s_1|x)p(x).\\] En este caso, en nuestros supuestos está la independencia condicional de \\(S_1\\) y \\(S_2\\) dado \\(X\\), que explicaremos con detalle más adelante. El diagrama relevante es\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X \n    S1 [label = <S<SUB>1</SUB>>]\n    S2 [label = <S<SUB>2</SUB>>]\n  edge [minlen = 3]\n    X -> S1\n    X -> S2\n{ rank = same; S1; S2 }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nY podemos hacer simulaciones de este proceso generador:\n\nsimular_dos <- function(n = 10, x = NULL){\n  if(is.null(x)){\n    x <- runif(n)\n  }\n  s_1 <- rbinom(n, 5, prob = x)\n  s_2 <- rbinom(n, 5, prob = x)\n  tibble(x = x, s_1 = s_1, s_2 = s_2)\n}\nset.seed(116)\nsims_monedas <- simular_dos(5000)\nhead(sims_monedas)\n\n# A tibble: 6 × 3\n      x   s_1   s_2\n  <dbl> <int> <int>\n1 0.741     4     4\n2 0.336     5     2\n3 0.193     1     1\n4 0.281     1     2\n5 0.998     5     5\n6 0.534     3     5\n\n\nNótese que aún cuando simulamos independientemente \\(S_1\\) y \\(S_2\\) una vez que tenemos el dado, \\(S_1\\) y \\(S_2\\) no son independientes:\n\nggplot(sims_monedas, aes(x = s_1, y = s_2)) + geom_jitter(width = 0.25, height = 0.25)\n\n\n\n\n\nCuando no conocemos \\(X\\), saber \\(S_1\\) nos da información acerca de \\(S_2\\), porque saber \\(S_1\\) cambia la distribución de \\(X\\) (cuál es la probablidad de sol)\nSi no conocemos \\(X\\), la información puede fluir de \\(S_1\\) a \\(S_2\\).\n\n\n\n2.2.2 Ejemplo\nRegresamos al ejemplo de estatura y peso. Supongamos que agregamos una variable adicional \\(S\\) que vale 1 cuando la persona es hombre y 0 si no. Podemos discutir distintas maneras de construir nuestro modelo, por ejemplo, supongamos que usamos:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    S \n    H \n    W\n  edge [minlen = 3]\n    S -> H\n    H -> W\n    S -> W\n{ rank = same; S; H; W }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso, para definir nuestro modelo generativo tenemos que definir \\(p(z)\\), \\(p(h|z)\\) y finalmente \\(p(w|h,z)\\). En este caso, consideramos que además de que los hombres tienen estatura mayor y por tanto mayor peso, existe un efecto adicional que, entre hombres y mujeres de la misma estatura, los hombres tienden a ser más un poco más pesados.\n\nEntender la diferencia y cuantificar el efecto de hombre-mujer sobre peso a través de estatura y el efecto directo es importante y veremos cómo hacerlo más adelante, y bajo qué condicinoes es posible.\n\nEn este modelo, podríamos argumentar que hay, por ejemplo:\n\nMuchas causas de sexo que podríamos considerar, pero no nos interesan pues nuestras preguntas están relacionadas con el efecto de sexo. Si esas variables pudieran influír causalmente tanto a sexo como a peso, entonces deberíamos incluirlas, como veremos más adelante.\nTambién sabemos que hay muchas causas comunes de altura y peso. Por ejemplo, nutrición o medio ambiente. Si esas causas no influyen también a sexo, entonces veremos más adelante por qué no es necesario que las incluyamos para la pregunta particular que estamos formulando en este ejemplo (el efecto total de sexo).\n\nDada el diagrama, consideramos un modelo generativo como sigue:\n\nmod_peso <- cmdstanr::cmdstan_model(\"../src/peso_estatura_2.stan\")\nprint(mod_peso)\n\ndata {\n  int<lower=0> N;\n}\n\nparameters {\n}\n\ntransformed parameters {\n}\n\nmodel {\n\n}\ngenerated quantities {\n  int<lower=0> s;\n  real<lower=0> h;\n  real<lower=0> w;\n\n    // simulamos hombre o mujer\n    s = bernoulli_rng(0.5);\n    // simular estatura dado el sexo\n    real m_h = 15 * s + 160;\n    h = normal_rng(m_h, 12);\n    // simular peso dado estatura y sexo\n    real m_w = -50 + 5 * s + 0.7 * h;\n    w = normal_rng(m_w, 10);\n}\n\n\n\ndatos_lista <- list(N = 500)\najuste <- mod_peso$sample(data = datos_lista, refresh = 1000, fixed_param = TRUE)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 2 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 3 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 4 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"s\", \"h\", \"w\"), format = \"df\")\nresumen <- ajuste$summary(c(\"h\", \"w\"))\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 2 × 4\n  variable  mean    q5   q95\n  <chr>    <dbl> <dbl> <dbl>\n1 h        168.  144.  191. \n2 w         70.1  45.3  95.1\n\n\n\nggplot(sims, aes(x = h, y = w, colour = factor(s))) + geom_point() +\n  geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\n\n\nModelos lineales\n\n\n\n\nEn estos ejemplos, estamos usando modelos lineales sin interacciones, pero en realidad podríamos incluír no linealidad (en forma de splines o modelos teóricos) o interacciones, por ejemplo\nEn todos los casos, es importante checar los modelos que hemos construido (ver flujo bayesiano).\n\n\n\nEjercicios:\n\nConstruye un modelo quitando la flecha \\(S\\to W\\).\nConstruye un modelo donde \\(H\\) y \\(S\\) interactúan para determinar \\(W\\).\n¿Qué modelos son más simples en términos de parámetros que son necesarios para definirlos?"
  },
  {
    "objectID": "02-modelos-graficos.html#variables-observadas-y-no-observadas",
    "href": "02-modelos-graficos.html#variables-observadas-y-no-observadas",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.3 Variables observadas y no observadas",
    "text": "2.3 Variables observadas y no observadas\nNótese que en muchos casos, la estructura que genera los datos puede incluir variables que no hemos medido. No siempre es una buena idea quitar estas variables porque simplemente nos las conocemos. Dado el proceso generador, no tendría mucho sentido escribir \\(S_1 \\to S_2\\) o \\(S_2 \\to S_1\\) (aunque podríamos construir tales modelos).\nEn este caso, podríamos mejor escribir:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    X\n  node [shape=plaintext]\n    S1 [label = <S<SUB>1</SUB>>]\n    S2 [label = <S<SUB>2</SUB>>]\n  edge [minlen = 3]\n    X -> S1\n    X -> S2\n{ rank = same; S1; S2 }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nLa estructura del modelo junto con la naturaleza de las relaciones que conocemos nos permitirá hacer inferencia sobre esas variables no observadas, por ejemplo:\n\nmod_monedas <- cmdstanr::cmdstan_model(\"../src/monedas.stan\")\nprint(mod_monedas)\n\ndata {\n  int<lower=0> s_1;\n  int<lower=0> s_2;\n}\nparameters {\n  real<lower=0, upper = 1> x;\n}\nmodel {\n  x ~ uniform(0, 1);\n  s_1 ~ binomial(5, x);\n  s_2 ~ binomial(5, x);\n}\n\n\n\ndatos_lista <- list(s_1 = 5, s_2 = 3)\najuste <- mod_monedas$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"x\"), format = \"df\")\nresumen <- ajuste$summary(c(\"x\"))\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable  mean    q5   q95\n  <chr>    <dbl> <dbl> <dbl>\n1 x        0.751 0.529 0.920\n\n\nDe modo que con alta probabilidad, escogimos una \\(X\\) entre .5 y 0.93.\n\n2.3.1 Ejemplo (estudio de Santa Clara)\nEn 2020 se hizo un estudio de seroprevalencia de COVID en Santa Clara, California.\nSe tomó una muestra de individuos (ver los detalles en el artículo original). Para propósitos de este análisis supondremos que la muestra puede considerarse como aleatoria simple.\nSe obtuvieron 3,300 individuos, y 50 de ellos resultaron con prueba positiva (1.5%). Sin embargo, el kit de prueba que estaban utilizando, tienen cierta especificidad y sensibilidad menores a 1. En pruebas de gold standard, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas.\nConstruiremos ahora una gráfica que indica cómo es el proceso generador de datos. En primer lugar, no interesa estimar la seropositividad en una población dada, que suponemos fue muestreada al azar. Nosotros solamente observamos si la prueba que usamos es positiva o negativa. Escribimos entonces para empezar:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    prev\n    Inf\n  node [shape=plaintext]\n    Inf\n    Positivos\n    N\n    \n  edge [minlen = 3]\n    prev -> Inf\n    Inf -> Positivos\n    N -> Inf\n    \n}\n\", width = 150, height = 60)\n\n\n\n\n\n\nNótese que estamos pensando de forma causal al dibujar las aristas:\n\n\\(N\\) (el tamaño de muestra) es una variable que controlamos. No está determinada por la prevalencia. La flecha debe ser \\(prev \\to Inf\\), pues sabemos que si la prevalencia es diferente, entonces el número de personas con infección previa tiene una distribución diferente. Sin embargo, si intervenimos y cambiamos por alguna razón la variable \\(Inf\\), claramente esto no tiene ningún efecto en \\(p\\) ni en \\(N\\).\n\\(Inf\\) influye en la distribución de positivos, y el número de positivos está determinado solamente por las características de la prueba. Nótese que si sabemos \\(Inf\\), entonces el número de positivos no influye en en \\(p\\) ni en \\(N\\), y que cambiar la prueba por ejemplo, no cambia la distribución de la variable \\(Inf\\). De modo que la única flecha que debemos agregar es \\(Inf \\to Positivos\\).\nAunque podríamos agregar muchos factores que influyen en la prevalencia, estas variables no afectan directamente a otras variables de nuestro diagrama. Dado que no nos interesa contestar este tipo de preguntas, omitimos estas variables.\n\nUn camino sería ahora decidir que \\(Inf=Positivos\\), es decir no son releventes las características de la prueba, y proceder con la inferencia. Sin embargo, la pregunta qué tenemos qué hacer, es ¿puede ser que las características de la prueba influyan considerablemente en las estimaciones que obtenemos?\nAntes de proceder a incluir las características de la prueba, haremos el análisis pensando que el error de medición no es importante:\n\n#! message: false\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\nmod_sc <- cmdstan_model(\"../src/sclara-simple.stan\")\nprint(mod_sc)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n;\n}\n\nparameters {\n  real<lower=0, upper=1> p; //seroprevalencia\n\n}\n\ntransformed parameters {\n  real<lower=0, upper=1> prob_pos;\n\n  prob_pos = p;\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  p ~ beta(1.0, 10.0);\n}\n\n\n\nn <- 50\nN <- 3300\ndatos_lista <- list(N = 3300, n = 50)\najuste <- mod_sc$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"p\"), format = \"df\")\nresumen <- ajuste$summary(c(\"p\"))\n\n\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean     q5    q95\n  <chr>     <dbl>  <dbl>  <dbl>\n1 p        0.0154 0.0120 0.0192\n\n\nY podemos graficar la posterior de la seroprevalencia:\n\nggplot(sims, aes(x = p)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nDonde parece ser que la prevalencia está muy probablemente por arriba de 1.2% Si este es el caso, esto implicaría que el subconteo de infecciones era muy grande, y que el IFR es más bajo de lo que se creía.\nSin embargo, observamos positivos en la prueba, y no realmente si alguien se ha infectado o no. Ahora incluimos sensibilidad y especificidad:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    prev\n    Inf\n    sens\n    esp\n  node [shape=plaintext]\n    Inf\n    Positivos\n    N\n\n  edge [minlen = 3]\n    prev -> Inf\n    Inf -> Positivos\n    N -> Inf\n    sens -> Positivos\n    esp -> Positivos\n}\n\", width = 150, height = 60)\n\n\n\n\n\n\n\nNótese que sens y esp, si las modificamos, no cambian nada de \\(N\\), \\(Inf\\), ni la prevalencia. Igualmente, las flechas deben ir hacia \\(Inf\\), pues modificar esta cantidad no produce cambios en las características de la prueba.\nPara entender si tenemos que agregar una flecha de sensibilidad a especificidad tendríamos que pensar en el proceso que genera estas variables. Podemos pensar en primer lugar que una variable común que determina estas dos cantidades es, por ejemplo, la curva ROC de la prueba que produciría una asociación negativa en estas variables. En un ejercicio más adelante exploraremos esto, pero por el momento no consideramos esto (por ejemplo, podría ser que existiera una relación inversa entre especificidad y sensibilidad, que depende de la curva ROC).\n\nFinalmente, tenemos los datos de las pruebas de gold estándar que se hicieron para las pruebas. Esto incluye cuantos casos verificados positivos/negativos se les aplicó la prueba, cuántos casos fueron correctamente clasificados por la prueba en cada caso. Dibujamos entonces:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    sens\n    esp\n    prev\n    Inf\n  node [shape=plaintext]\n    Inf\n    Positivos\n    npos\n    poskit\n    nneg\n    negkit\n    N\n    \n  edge [minlen = 3]\n    npos -> poskit\n    sens -> poskit\n    nneg -> negkit\n    esp -> negkit\n    prev -> Inf\n    Inf -> Positivos\n    sens -> Positivos\n    esp -> Positivos\n    N -> Inf\n    \n}\n\", width = 150, height = 60)\n\n\n\n\n\n\n\nLas flechas que acabamos de dibujar corresponden a la discusión que tenemos arriba. Por ejemplo, cambiar \\(esp\\) cambia la distribución de el número de negativos que obtuvimos, pero intervenir en el número de negativos (por ejemplo, escogiendo las personas que se ven sanas para hacerse la prueba y descartar a otro) no tiene efecto sobre \\(esp\\).\n\nAhora escribimos los modelos locales siguiendo los supuestos que acabamos de establecer, que en este caso están determinados:\n\nlibrary(cmdstanr)\nmod_sc <- cmdstan_model(\"../src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n;\n  int<lower=0> kit_pos;\n  int<lower=0> n_kit_pos;\n  int<lower=0> kit_neg;\n  int<lower=0> n_kit_neg;\n}\n\nparameters {\n  real<lower=0, upper=1> p; //seroprevalencia\n  real<lower=0, upper=1> sens; //sensibilidad\n  real<lower=0, upper=1> esp; //especificidad\n}\n\ntransformed parameters {\n  real<lower=0, upper=1> prob_pos;\n\n  prob_pos = p * sens + (1 - p) * (1 - esp);\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  // modelos para resultados del kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales para cantidades no medidas\n  p ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\n\nn <- 50\nN <- 3300\ndatos_lista <- list(N = 3300, n = 50,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste <- mod_sc$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"p\", \"sens\", \"esp\"), format = \"df\")\nresumen <- ajuste$summary(c(\"p\"))\n\n\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean      q5    q95\n  <chr>     <dbl>   <dbl>  <dbl>\n1 p        0.0102 0.00213 0.0176\n\n\nY podemos graficar la posterior de la seroprevalencia:\n\nggplot(sims, aes(x = p)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nY vemos que los datos son consistentes con el dato reportado por los autores (alrededor de 1.2%), pero que no podemos excluir valores de prevalencia muy bajos (por abajo de 0.3% por ejemplo). Por otro lado, también son consistentes valores muy altos de seroprevalencia, de manera que este estudio resultó ser poco informativo de la IFR del COVID.\nPodemos hacer diagnósticos adicionales acerca de la razón de esta variabilidad alta, si graficamos la relación entre especificidad de la prueba y estimación de prevalencia:\n\nggplot(sims, aes(x = esp, y = p)) + geom_point() +\n  xlab(\"Especificidad del kit\") + ylab(\"Prevalencia\") + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nLa asociación entre estas dos cantidades es interesante porque conceptualmente (y desde punto de vista del modelo), no hay relación entre estas dos variables: su asociación aparece porque son causas que compiten para explicar una observación.\nAunque aprender el flujo de construcción y validación de modelos en todos sus aspectos no es el objetivo de este curso, mostramos un resumen abajo:\n\n\n\n\n\n\nDesarrollo de modelos\n\n\n\n\nEstablecer la pregunta que queremos contestar\nEspecificar nuestros supuestos causales\nDefinir un modelo generativo dado el paso anterior\nDefinir una estrategia para contestar la pregunta de 1)\nProbar el modelo y nuestra estrategia usando el modelo generativo\nAnalizar datos con el modelo, checar supuestos y resumir."
  },
  {
    "objectID": "02-modelos-graficos.html#independencia-condicional",
    "href": "02-modelos-graficos.html#independencia-condicional",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.4 Independencia condicional",
    "text": "2.4 Independencia condicional\nRecordamos el concepto de independencia condicional, que está relacionado a cómo se puede factorizar una conjunta:\n\n\n\n\n\n\nIndependencia condicional\n\n\n\nSean \\(X,Y,Z\\) variables aleatorias. Decimos que \\(X\\) y \\(Y\\) son condicionalmente independientes dado \\(Z\\) cuando se satisface \\[p(x,y|z) = p(x|z)p(y|z)\\] o equivalentemente, \\[p(x|y,z) = p(x|z)\\]\n\n\nEn palabras: si conocemos el valor de \\(Z\\), \\(X\\) y \\(Y\\) ya no están asociadas, o si ya condicionamos a z, entonces condicionar adicionalmente a \\(Y\\) no cambia la distribución condicional de \\(X\\). Para ver por qué las dos formas son equivalentes recuerda que cualquier regla de probabilidad general puede condicionarse a cualquier infromación y sigue siendo una regla válida. Como de mostramos que \\(p(x,y) = p(x)p(y)\\) si y sólo si \\(p(y|x) = p(y)\\), podemos obtener una regla válida condicionando todo a \\(Z\\).\nEste concepto en la modelación e interpretación, por ejemplo en el caso de Santa Clara, prevalencia y número de positivos son dependientes. Pero si conocemos el número de infectados, prevalencia y positivos son condicionalmente independientes, y esto es una idea importante este modelo.\nEn nuestro primer ejemplo de la sección anterior, observamos que una vez que sabíamos \\(X\\), la probabilidad de sol, no hay relación entre \\(S_1\\) y \\(S_2\\), aún cuando no es cierto que \\(p(s_1,s_2) = p(s_1)p(s_2)\\).\nPodemos checar esto en las simulaciones, por ejemplo:\n\nset.seed(812)\nsimular_dos(1e5, x = 0.4) |> \n  select(s_1, s_2) |> \n  group_by(s_1, s_2) |> \n  count() |> \n  group_by(s_1) |> \n  mutate(prop_cond = n / sum(n)) |> \nggplot(aes(x = s_2, y = prop_cond, colour = s_1, group = factor(s_1))) +\n  geom_line()\n\n\n\n\nLas condicionales son iguales en cada caso, de modo que \\(S_1\\) y \\(S_2\\) son independientes dada \\(X\\) (prueba con otros valores de \\(X\\))."
  },
  {
    "objectID": "02-modelos-graficos.html#gráficas-dirigidas-acíclicas",
    "href": "02-modelos-graficos.html#gráficas-dirigidas-acíclicas",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.5 Gráficas dirigidas acíclicas",
    "text": "2.5 Gráficas dirigidas acíclicas\nPara representar gráficamente la construcción de modelos que hemos considerado, podemos usar las siguiente idea:\n\n\n\n\n\n\nNota\n\n\n\nDecimos que una gráfica dirigida \\(G\\) representa a una conjunta \\(p(x_1,\\ldots, x_p)\\) cuando podemos factorizar\n\\[p(x_1,\\ldots, x_p) = \\prod_{i=1}^p p(x_i | pa(x_i))\\]\ndonde \\(pa(x_i)\\) son los padres del nodo X_i en la gráfica G.\n\n\n\n2.5.0.1 Ejemplo\nConsideramos la siguiente gráfica:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Ob\n    Fuma\n    EC \n    Tos\n  edge [minlen = 3]\n   Ob -> EC\n   Fuma -> EC\n   Fuma -> Tos\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEsta gráfica representa una conjunta \\(p(o,f,c,t)\\) cuando es posible factorizar\n\\[p(ob,f,ec,t) = p(f)p(o)p(ec|o,f)p(t|f),\\]\nde forma que podemos entender el proceso generador de este conjunto de variables como sigue: simulamos primero \\(F\\) y \\(Ob\\), usando el valor de \\(F\\) podemos simular \\(T\\), y usando el valor de \\(F\\) y \\(Ob\\) podemos simular \\(C\\). En este ejemplo podemos pensar que las variables son Obesidad, Fumador, Enfermedad de Corazón y Tos. Nótese que la distribución de Enfermedad de Corazón depende del estado de Obesidad y fumador. La probabilidad de tener tos depende directamente del estado de fumador.\nEl conjunto de independencias condicionales de una conjunta \\(p\\) está fuertemente ligado a la estructura de la gráfica que la representa:\n\n\n\n\n\n\nNota\n\n\n\nUna distribución \\(p\\) es representada por \\(G\\) si y sólo si para cada variable \\(W\\), cuando condicionamos a los padres \\(pa(W)\\) de \\(W\\), \\(W\\) es condicionalmente independiente de todas las variables que no son descendientes o padres de \\(W\\).\n\n\nEs decir, si condicionamos a los padres de una variable, esta variable es condicionalmente independiente del “pasado”, en el sentido del orden de la gráfica. Estas no son las únicas independencias condicionales que están presentes, veremos que para calcular éstas es necesario usar el concepto de d-separación. Antes discutiremos las estructuras básicas que nos interesan estudiar en una gráfica.\n\n\n2.5.1 Independencia condicional, parsimonia y supuestos\nLa independencia condicional es un concepto central para construir modelos probabilísticos, pues nos permite construir modelos parsimoniosos.\n\nEn una factorización dada, cada factor representa un modelo distinto, que puede tener parámetros que definen la relación entre la variable resultante y sus padres.\nSi en nuestro modelo existen independencias condicionales, podemos hacer modelos con menos parámetros, y cada relación es más simple.\n\nEn nuestro ejemplo anterior, si \\(T\\) tuviera más padres en lugar de tener que definir o estimar \\(p(t|f)\\), tendríamos que modelar \\(p(t|o,f,c)\\), que es un modelo más complicado: por ejemplo, puede tener interacciones complicadas y no linealidades más complejas que el modelo \\(f(t|f)\\)\nAdicionalmente, el conjunto de independencias condicionales también nos dice que implicaciones tiene el modelo que estamos considerando. Más adelante veremos cómo:\n\nCalcular todas las independencias condicionales dada nuestra gráfica\nEntender en qué lugares puede haber dependencias y explicar la razón de su existencia, por ejemplo, si la relación es causal o no.\n\nPor ejemplo, cuando consideramos las dos colecciones de volados (\\(S_1\\) y \\(S_2\\)) dada una misma moneda (\\(X\\)), podemos entender por qué \\(S_1\\) y \\(S_2\\) no son independientes: saber el resultado de \\(S_1\\), por ejemplo, nos da información acerca la \\(X\\), lo cual a su vez nos da información de \\(S_2\\). La información fluye a lo largo de la gráfica correspondiente dado el supuesto que hicimos que las dos series de volados se hacen con una moneda."
  },
  {
    "objectID": "02-modelos-graficos.html#estructuras-básicas-en-dags",
    "href": "02-modelos-graficos.html#estructuras-básicas-en-dags",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.6 Estructuras básicas en DAGs",
    "text": "2.6 Estructuras básicas en DAGs\nVeremos que para razonar acerca de las asociaciones e independencias que pueden aparecer en una conjunta, podemos examinar la gráfica que la represente, o dicho de otra manera, entender bajo qué condiciones puede propagarse información de un nodo a otro.\nConsideremos entonces tres variables \\(X\\), \\(Y\\) y \\(Z\\). Las tres estructuras que tenemos que entender en primer lugar pueden verse también como métodos de razonamiento lógico derivados de las leyes de probabilidad:\n\n2.6.1 Cadenas o mediación\nEn este caso tenemos:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   X -> Z\n   Z -> Y\n}\n\", width = 150, height = 20)\n\n\n\n\n\n\nEn este caso,\n\nExiste asociación entre \\(X\\) y \\(Y\\), pero no existe relación directa entre ellas.\nSi condicionamos a un valor de \\(Z\\), \\(X\\) y \\(Y\\) son condicionalmente independientes.\n\nPodemos pensar en \\(Z\\) como un mediador del efecto de \\(X\\) sobre \\(Y\\). Si no permitimos que \\(Z\\) varíe, entonces la información de \\(X\\) no fluye a \\(Y\\).\nPor ejemplo, si \\(X\\) tomar o no una medicina para el dolor de cabeza, \\(Z\\) es dolor de cabeza y \\(Y\\) es bienestar general, \\(X\\) y \\(Y\\) están relacionadas. Sin embargo, si condicionamos a un valor fijo de dolor de cabeza, no hay relación entre tomar la medicina y bienestar general.\nEn términos de factorización, podemos checar la independencia condicional: como \\(p(x,y,z) = p(x)p(z|x)p(y|z)\\), entonces\n\\[p(x, y | z) = p(x,y,z) / p(z) = (p(x)(z|x)) (p(y|z) / p(z))\\] y vemos que el lado izquierdo se factoriza en una parte que sólo involucra a \\(x\\) y \\(z\\) y otro factor que sólo tiene a \\(y\\) y \\(z\\): no hay términos que incluyan conjuntamente a \\(x\\), \\(y\\) y \\(z\\). Podemos de cualquier forma continuar notando\n\\[p(x)p(z|x)/p(z) = p(x,z)/p(z) = p(x | z)\\] de modo que\n\\[p(x, y | z) = p(x|z) p(y|z) \\]\nY mostramos un ejemplo simulado:\n\nrbern <- function(n, prob){\n  rbinom(n, 1, prob = prob)\n} \nsimular_mediador <- function(n = 10){\n  x <- rbern(n, p = 0.5) |> as.numeric()\n  z <- rbern(n, p = x * 0.8 + (1 - x) * 0.3)\n  y <- rbinom(n, 2, z * 0.7 + (1 - z) * 0.5)\n  tibble(x, z, y)\n}\nsims_mediador <- simular_mediador(50000)\n\n\\(X\\) y \\(Y\\) son dependientes:\n\nsims_mediador |> select(x, y) |> \n  count(x, y) |> \n  group_by(x) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1:\n\nsims_mediador |> \n  count(x, y, z) |> \n  group_by(x, z) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, z, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\nY vemos que la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) sólo depende de \\(Z\\). Una consecuencia es por ejemplo que la correlación debe ser cero:\n\ncor(sims_mediador |> filter(z == 1) |> select(x,y)) |> round(3)\n\n       x      y\nx  1.000 -0.004\ny -0.004  1.000\n\ncor(sims_mediador |> filter(z == 0) |> select(x,y)) |> round(3)\n\n      x     y\nx 1.000 0.004\ny 0.004 1.000\n\n\nPodemos también hacer un ejemplo continuo:\n\nsimular_mediador <- function(n = 10){\n  x <- rnorm(n, 100, 10)\n  prob <- 1 / (1 + exp(-(x - 100)/5))\n  z <- rbern(n, p = prob)\n  y <- rnorm(n, 100 + 30 * z, 15)\n  tibble(x, z, y)\n}\nsims_mediador <- simular_mediador(2000)\n\n\\(X\\) y \\(Y\\) son dependientes (por ejemplo si vemos la media condicional de \\(Y\\) dado \\(X\\):\n\nggplot(sims_mediador, aes(x = x, y = y, colour = z)) + geom_point() +\n  geom_smooth(span = 1)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nSi condicionamos a \\(Z\\), no hay dependencia entre \\(X\\) y \\(Y\\)\n\nggplot(sims_mediador, aes(x = x, y = y, colour = z, group = z)) + \n  geom_point() +\n  geom_smooth(span = 2)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n2.6.2 Bifurcaciones o causa común\nEn el siguiente ejemplo, llamamos a \\(Z\\) una causa que es común a \\(X\\) y \\(Y\\).\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   Z -> X\n   Z -> Y\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso,\n\n\\(X\\) y \\(Y\\) tienen asociación\nSi condicionamos a \\(Z\\), entonces \\(X\\) y \\(Y\\) son condicionalmente independientes.\n\nEste tipo de estructura también se llama bifurcación, o decimos que \\(Z\\) es un confusor en esta gráfica. Variación en \\(Z\\) produce variación conjunta de \\(X\\) y \\(Y\\).\nPor ejemplo, podríamos encontrar que el uso de aspirina \\(X\\) está asociado a una mortalidad más alta \\(Y\\). Una causa común es enfermedad grave que produce dolor (\\(Z\\)). Sin embargo, si condicionamos a personas sanas, veríamos que no hay relación entre uso de aspirina y mortalidad, igualmente veríamos que entre las personas enfermas el uso de aspirina no les ayuda a vivir más tiempo.\nEn este caso, tenemos:\n\\[p(x, y, z) =  p(z)p(x|z)p(y|z)\\] Y como el lado izquierdo es igual (en general) a \\(p(x,y|z)p(z)\\), obtenemos la independiencia condicional de \\(X\\) y \\(Y\\) dado \\(Z\\).\n\nrbern <- function(n, prob){\n  rbinom(n, 1, prob = prob)\n} \nsimular_confusor <- function(n = 10){\n  z <- rbern(n, p = 0.5) |> as.numeric()\n  x <- rbern(n, p = z * 0.3 + (1 - z) * 0.8)\n  y <- rbinom(n, 4, z * 0.9 + (1 - z) * 0.3)\n  tibble(x, z, y)\n}\nsims_confusor <- simular_confusor(50000)\n\n\\(X\\) y \\(Y\\) son dependientes:\n\nsims_confusor |> select(x, y) |> \n  count(x, y) |> \n  group_by(x) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1:\n\nsims_confusor |> \n  count(x, y, z) |> \n  group_by(x, z) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, z, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\nY vemos que la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) sólo depende de \\(Z\\). Una consecuencia es por ejemplo que la correlación debe ser cero:\n\ncor(sims_confusor |> filter(z == 1) |> select(x,y)) |> round(3)\n\n      x     y\nx 1.000 0.008\ny 0.008 1.000\n\ncor(sims_confusor |> filter(z == 0) |> select(x,y)) |> round(3)\n\n      x     y\nx 1.000 0.015\ny 0.015 1.000\n\n\n\nsimular_bifurcacion <- function(n = 10){\n  z <- rbern(n, p = 0.5)\n  x <- rnorm(n, 100 + 20 * z, 15)\n  y <- rnorm(n, 100 + 30 * z, 20)\n  tibble(x, z, y)\n}\nsims_bifurcacion <- simular_bifurcacion(5000)\n\n\\(X\\) y \\(Y\\) son dependientes (por ejemplo si vemos la media condicional de \\(Y\\) dado \\(X\\):\n\nggplot(sims_bifurcacion, aes(x = x, y = y, colour = z)) + \n  geom_point(alpha = 0.2) +\n  geom_smooth(span = 1)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nSi condicionamos a \\(Z\\), no hay dependencia entre \\(X\\) y \\(Y\\)\n\nggplot(sims_bifurcacion, aes(x = x, y = y, colour = z, group = z)) + \n  geom_point(alpha = 0.2) +\n  geom_smooth(span = 2)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n2.6.3 Colisionador o causas alternativas\nEn este caso, a \\(Z\\) también le llamamos un colisionador. Este es el caso que puede ser más difícil de entender en un principio.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   X -> Z\n   Y -> Z\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\n\nEn este caso \\(X\\) y \\(Y\\) son independientes\nSin embargo, si condicionamos a \\(Z\\) entonces \\(X\\) y \\(Y\\) están asociados.\n\nPor ejemplo, si observamos que el pasto está mojado, entonces saber que no llovió implica que probablemente se encendieron los aspersores.\nComo la conjunta se factoriza como:\n\\[p(x,y,z) = p(x)p(y)p(z|x,y)\\] podemos integrar sobre \\(Z\\):\n\\[p(x,y) = \\int p(x,y,z)dz = p(x)p(y)\\int p(z|x,y)\\, dz\\] pero \\(p(z|x,y)\\) integra uno porque es una densidad, de forma que \\(x\\) y \\(y\\) son independientes.\nY mostramos un ejemplo simulado:\n\nsimular_colisionador <- function(n = 10){\n  x <- rbern(n, 0.5) \n  y <- rbinom(n, 2, 0.7)\n  z <- rbern(n, p = 0.1 + 0.7 * x * (y > 1)) \n  tibble(x, z, y)\n}\nsims_colisionador <- simular_colisionador(50000)\n\n\\(X\\) y \\(Y\\) son independientes:\n\nsims_colisionador|> select(x, y) |> \n  count(x, y) |> \n  group_by(x) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1:\n\nsims_colisionador |> \n  count(x, y, z) |> \n  group_by(x, z) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, z, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\nY vemos que la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) depende de \\(X\\) y de \\(Z\\).\nLas correlaciones condicionales, por ejemplo, no son cero:\n\nprint(\"Dado Z = 0\")\n\n[1] \"Dado Z = 0\"\n\ncor(sims_colisionador |> filter(z == 0) |> select(x,y)) |> round(3)\n\n       x      y\nx  1.000 -0.287\ny -0.287  1.000\n\nprint(\"Dado Z = 1\")\n\n[1] \"Dado Z = 1\"\n\ncor(sims_colisionador |> filter(z == 1) |> select(x,y)) |> round(3)\n\n      x     y\nx 1.000 0.373\ny 0.373 1.000\n\n\nOtro ejemplo con variables continuas:\n\nsimular_colisionador_2 <- function(n = 10){\n  x <- rnorm(n, 100, 20) \n  y <- rnorm(n, 100, 20)\n  z <- rbern(n, p = 0.92 * ((x + y) > 220) + 0.05) \n  tibble(x, z, y)\n}\nsims_colisionador <- simular_colisionador_2(1000)\n\n\\(X\\) y \\(Y\\) son independientes:\n\nggplot(sims_colisionador, aes(x = x, y = y)) + geom_point()\n\n\n\n\nSin embargo, si condicionamos a un valor de \\(Z\\), \\(X\\) y \\(Y\\) ya no son independientes:\n\nggplot(sims_colisionador, aes(x = x, y = y, group = z, colour = factor(z))) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE) \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nY vemos que condicional a \\(Z\\), \\(X\\) y \\(Y\\) no son dependientes.\n\n\n2.6.4 Razonamiento de descendientes de efecto común\nCondicionar a un descendiente de un colisionador también produce dependencias condicionales:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n    A\n  edge [minlen = 3]\n   X -> Z\n   Y -> Z\n   Z -> A\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso,\n\n\\(X\\) y \\(Y\\) son independientes\n\\(X\\) y \\(Y\\) son dependientes si condicionamos a \\(A\\).\n\nDependiendo de la naturaleza de la asociación entre el colisionador \\(Z\\) y su descendiente \\(A\\), esta dependencia puede ser más fuerte o más débil.\nPor ejemplo, en nuestro ejemplo donde el pasto mojado es un colisionador entre cuánta agua dieron los aspersores y cuánta lluvia cayó, un descendiente del pasto mojado es el estado de las plantas del jardín. Aunque los aspersores trabajan independientemente de la lluvia, si observamos que las plantas se secaron entonces lluvia y aspersores están correlacionados: por ejemplo, si noto que los aspersores están descompuestos, entonces concluimos que no hubo lluvia.\n\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X [label = lluvia]\n    Y [label = aspersores]\n    Z [label = humedad]\n    A [label = plantas]\n  edge [minlen = 3]\n   X -> Z\n   Y -> Z\n   Z -> A\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\n\n2.6.5 Ejemplo: dependencias de colisionador\nVerificamos que en nuestro modelo de Santa Clara, efectivamente nuestro modelo no implica ninguna dependencia no condicional entre sensibilidad de la prueba y prevalencia. Eso debería ser claro de la simulación, pero de todas formas lo checamos\n\nlibrary(cmdstanr)\nmod_sc <- cmdstan_model(\"../src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n;\n  int<lower=0> kit_pos;\n  int<lower=0> n_kit_pos;\n  int<lower=0> kit_neg;\n  int<lower=0> n_kit_neg;\n}\n\nparameters {\n  real<lower=0, upper=1> p; //seroprevalencia\n  real<lower=0, upper=1> sens; //sensibilidad\n  real<lower=0, upper=1> esp; //especificidad\n}\n\ntransformed parameters {\n  real<lower=0, upper=1> prob_pos;\n\n  prob_pos = p * sens + (1 - p) * (1 - esp);\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  // modelos para resultados del kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales para cantidades no medidas\n  p ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\nEn este caso, no pondremos información acerca de positivos en la prueba:\n\ndatos_lista <- list(N = 0, n = 0,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste <- mod_sc$sample(data = datos_lista, refresh = 1000, iter_sampling = 400)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 1 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 1 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 2 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 2 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 3 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 3 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 4 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 4 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"p\", \"sens\", \"esp\"), format = \"df\")\nresumen <- ajuste$summary(c(\"p\"))\n\n\nggplot(sims, aes(x = p, y = sens)) + geom_point() +\n  scale_x_sqrt()\n\n\n\n\nNo vemos ninguna asocación entre estas dos variables. Podemos hacer algunas permutaciones al azar para checar que nuestra interpetación de la gráfica es correcta:\n\nlibrary(nullabor)\nggplot(lineup(null_permute(\"p\"), sims, n = 5), aes(x = p, y = sens)) +\n  geom_point(alpha = 0.3) + facet_wrap(~ .sample) +\n  scale_x_sqrt()\n\ndecrypt(\"0lta Uo1o uQ OhHu1uhQ DD\")\n\n\n\n\n\nDonde no notamos ninguna diferencia sistemática después de hacer permutaciones.\nSin embargo, al condicionar al valor de Positivos, creamos una relación que no podemos interpretar como casual. En este caso particular supondremos prácticamente fija la sensibilidad para ver solamente lo que sucede en el colisionador de especificidad y número de positivos (la especificidad en este ejemplo es más crítica):\n\ndatos_lista <- list(N = 3300, n = 50,\n kit_pos = 1030000, n_kit_pos = 1220000, # números grandes para que esté practicamente\n# fija la sensibilidad\n kit_neg = 399, n_kit_neg = 401)\najuste <- mod_sc$sample(data = datos_lista, refresh = 1000, iter_sampling = 400)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 1 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 1 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 2 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 2 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 3 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 3 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 4 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 4 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"p\", \"sens\", \"esp\"), format = \"df\")\nresumen <- ajuste$summary(c(\"p\"))\n\n\nggplot(sims, aes(x = p, y = esp)) + geom_point() \n\n\n\n\nY vemos que condiconando al colisionador, obtenemos una relación fuerte entre prevalencia y especificidad de la prueba: necesitaríamos más datos de especificidad para obtener una estimación útil.\n\nLa razón de que la especificidad es más importante en este ejemplo es que la prevalencia es muy baja al momento del estudio, y los falsos positivos pueden introducir más error en la estimación\nTambién repetimos nótese que el análisis correcto de estos datos no se puede hacer con intervalos separados para cada cantidad, sino que debe examinarse la conjunta de estos parámetros.\n\n\nCon estas tres estructuras elementales podemos entender de manera abstracta la existencia o no de asociaciones entre nodos de cualquier gráfica dirigida."
  },
  {
    "objectID": "02-modelos-graficos.html#d-separación",
    "href": "02-modelos-graficos.html#d-separación",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.7 d-separación",
    "text": "2.7 d-separación\nAhora buscaremos describir todas las posibles independendencias condicionales y no condicionales que pueden aparecer en una gráfica, para entender cómo aparecen asociaciones entre variables de nuestro modelo, y dependiendo del tipo de condicionamiento que hacemos.\nVeremos que el criterio es algorítmico. Más adelante discutiremos cuáles de estas asociaciones se deben a efectos causales y cuáles no, y esto nos permitirá establecer estrategias de condicionamiento (qué variables controlar o no), recolección de datos para construir los estimadores correctos de los efectos causales de interés.\n\n\n\n\n\n\nd-separación: Caminos activos y bloqueados\n\n\n\n\nUn camino entre \\(X\\) y \\(Y\\) es una sucesión de aristas que conecta a \\(X\\) con \\(Y\\) (sin importar) la dirección de las aristas.\n\nAhora supongamos que \\(Z = \\{Z_1,Z_2,\\ldots, Z_q\\}\\) son una colección de nodos. Decimos que un camino \\(p\\) entre \\(X\\) y \\(Y\\) está activo condicional a los nodos en \\(Z\\) cuando:\n\nSiempre que hay un colisionador \\(X_i\\to Z\\gets X_j\\) en el camino \\(p\\), entonces \\(Z\\) o alguno de sus descendientes está en \\(Z\\).\nNingún otro nodo a lo largo de \\(p\\) está en \\(Z\\).\n\nEn caso contrario, decimos que el camino \\(p\\) está bloqueado.\nSi \\(Z\\) bloquea todos los caminos posibles entre \\(X\\) y \\(Y\\), decimos que \\(X\\) y \\(Y\\) están \\(d\\)-separados condicionalmente a \\(Z\\), o \\(d\\)-separados por \\(Z\\).\n\n\nSegún la discusión que tuvimos arriba de los modos de razonamiento en gráficas de modelos probabilísticos, el siguiente teorema no es sorpresa:\n\n\n\n\n\n\nCriterio de d-separación\n\n\n\nEn una DAG \\(G\\):\n\nSi dos variables están d-separadas por las variables \\(Z\\), entonces \\(X\\) y \\(Y\\) son condicionalmente independientes dadas las variables en \\(Z\\) para cualquier conjunta representada por \\(G\\).\nSi dos variables no están d-separadas por \\(Z\\), entonces existen conjuntas representadas por \\(G\\) tales que \\(X\\) y \\(Y\\) no tienen dependencia condicional dado \\(Z\\).\n\n\n\nNota 1: nótese que este teorema nos da una manera abstracta de razonar acerca de la asociación en un modelo gráfico: no es necesario saber la forma particular de las condicionales para utilizarlo.\nNota 2: Vale la pena mencionar que el segundo inciso en general es una implicación más fuerte: cuando no hay \\(d\\)-separación, existe algún tipo de dependencia casi seguro (en el sentido probabilístico de posible conjuntas).\nNota 3: Las independencias condicionales también pueden ser útiles para checar los supuestos de nuestro modelo: si encontramos asociaciones fuertes (condicionales o no) entre variables que nuestra estructura implica independencia condicional, entonces puede ser que nuestra estructura causal requiera revisión. Qué tanto podemos probar esto depende del tamaño de los datos que tengamos y de el tipo de condicionamiento que estamos haciendo.\nFinalmente (ver por ejemplo Koller y Friedman (2009), p 75), existe un algoritmo eficiente para encontrar todas las posibles independencias condicionales implicadas por una gráfica:\n\n\n\n\n\n\nCálculo de d-separación\n\n\n\nExiste un algoritmo de complejidad lineal en el tamaño de la gráfica para encontrar todos los nodos con caminos activos a un nodo \\(X\\) condicional a las variables \\(A\\).\n\n\nVer por ejemplo el sitio dagitty.net, donde podemos poner nuestra gráfica y enlistar todas los supuestos de independencia condicional implicados por un modelo.\n\nEjemplo\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Z \n    W \n    X\n    Y \n    U\n  edge [minlen = 3]\n    Z -> W\n    X -> W\n    X -> Y\n    W -> U\n    S -> Y\n    UZ -> Z\n    V -> Z\n    V -> S\n}\n\")\n\n\n\n\n\n\nConsideremos la relación entre Z y Y. Primero vemos que hay dos caminos entre \\(Z\\) y \\(Y\\), que son \\(p_1:X\\gets V \\to S\\) y \\(p_2: Z\\to W \\gets X \\to Y\\)\n\nEn primer lugar, ¿son independientes si no condicionamos a ninguna variable? No, pues el camino \\(p_1\\) es activo, e induce correlación.\n¿Son condicionalmente independientes si condicionamos a \\(V\\)? En este caso, condicionar a \\(V\\) bloquea el camino \\(p_1\\). El camino \\(p_2\\) está bloqueado por el colisionador \\(W\\), así que todos los caminos están bloqueados si condicionamos a \\(V\\).\nSi condicionamos a \\(W y V\\), ¿son independientes? No. El camino \\(p_1\\) está bloqueado, así que ese no induce asociación. Sin embargo, al condicionar al colisionador \\(W\\) activamos el camino \\(p_2\\).\nAhora supongamos que tenemos datos condicionales a algún valor de \\(W\\) solamente. Condicionando a \\(V\\) bloqueamos el camino \\(p_1\\), pero el camino \\(p_2\\) está activo. ¿Qué pasaría si condicionamos adicionalmente a \\(X\\)? En este caso, el conjunto de condicionamiento es \\(\\{V, W, X\\}\\). El camino \\(p_2\\) está bloqueado. Y aunque condicionamos al colisionador, \\(X\\) bloque el camino. Por lo tanto \\(Z\\) y \\(Y\\) son condicionalmente independientes dado \\(\\{V, W, X\\}\\).\n\n\n\n2.7.1 Ejercicio\nRepite el ejemplo anterior para la siguiente gráfica. Analiza que pasa si condicionamos o no a valores de \\(T\\), y qué pasa si adicionalmente condicionamos a \\(W\\), y luego repite los pasos del ejemplo anterior.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Z \n    W \n    X\n    Y \n    U\n    T\n  edge [minlen = 3]\n    T -> Z\n    T -> Y\n    Z -> W\n    X -> W\n    X -> Y\n    W -> U\n    S -> Y\n    UZ -> Z\n}\n\")"
  },
  {
    "objectID": "02-modelos-graficos.html#relación-con-inferencia-causal",
    "href": "02-modelos-graficos.html#relación-con-inferencia-causal",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.8 Relación con inferencia causal",
    "text": "2.8 Relación con inferencia causal\nSi el DAG que consideramos representa relaciones causales (mecanísticas) entre las variables, es decir, qué variable “escucha” a qué otras para decidir su valor, entonces podemos hacer una definición adicional\n\n\n\n\n\n\nCaminos causales\n\n\n\nEn un DAG, los caminos causales entre \\(X\\) y \\(Y\\) son de la forma \\(X\\to U_1\\to U_2 \\to \\cdots U_j \\to Y\\). Puede haber varios de ellos en un diagrama dado, y cada uno representa un mecanismo en que cambios en \\(X\\) producen cambios en \\(Y\\)\nSi nos interesa el efecto total de \\(X\\) sobre \\(Y\\),\n\nQueremos que todos los caminos causales de \\(X\\) a \\(Y\\) estén activos,\nQueremos condicionar para que todos los caminos no causales estén bloqueados, en particular, no queremos condicionar a colisionadores o sus descendientes que introduzcan relaciones no causales, y queremos bloquear caminos no casuales creados por bifurcaciones.\n\n\n\n\n\n\n\nKoller, D., y N. Friedman. 2009. Probabilistic Graphical Models: Principles and Techniques. MIT Press."
  },
  {
    "objectID": "99-referencias.html",
    "href": "99-referencias.html",
    "title": "Referencias",
    "section": "",
    "text": "Bishop, Christopher M. 2006. Pattern Recognition and Machine\nLearning (Information Science and Statistics). Secaucus, NJ, USA:\nSpringer-Verlag New York, Inc.\n\n\nJulious, Steven A, and Mark A Mullee. 1994. “Confounding and\nSimpson’s Paradox.” BMJ 309 (6967):\n1480–81. https://doi.org/10.1136/bmj.309.6967.1480.\n\n\nKoller, D., and N. Friedman. 2009. Probabilistic Graphical Models:\nPrinciples and Techniques. MIT Press."
  }
]
[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos analíticos",
    "section": "",
    "text": "Temario y referencias\nTodas las notas y material del curso estarán en este repositorio.\n\nParte 1: Inferencia causal\n\nIntroducción a inferencia causal\nModelos probabilísticos gráficos\nEstimación de efectos causales\nExperimentos y controles\nContrafactuales de Rubin\nOtros métodos de inferencia causal\n\nParte 2: Análisis de series de tiempo y pronósticos\n\nDescomposición de series de tiempo\nIngeniería de entradas para datos de series de tiempo\nMétodos clásicos para pronósticos\nModelo de espacio de estados\nInferencia causal para series de tiempo\n\n\n\nEvaluación\n\nTareas semanales (20%)\nExamen parcial (40% teórico)\nUn examen final (40% práctico)\n\n\n\nMaterial\nCada semestre las notas cambian, en algunas partes considerablemente. Las de este semestre están en este repositorio, incluyendo ejemplos, ejercicios y tareas.\n\n\nReferencias principales\n\nParte 1\n\nStatistical Rethinking\nCausal Inference in Statistics: a primer\nCounterfactuals and Causal Inference: Methods and Principles for Social Research\n\nParte 2:\n\nForecasting: Principles and Practice\nTime Series Analysis by State Space Methods\n\n\n\n\nOtras referencias\n\nPattern Recognition and Machine Learning, Bishop (2006)\nThe Book of Why\nData Analysis Using Regression and Multilevel/Hierarchical Models\nAn Introduction to State Space Time Series Analysis ### Software: R y Rstudio {-}\n\nPara hacer las tareas y exámenes pueden usar cualquier lenguaje o flujo de trabajo que les convenga (R o Python, por ejemplo) - el único requisito esté basado en código y no point-and-click.\n\n\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning (Information Science and Statistics). Secaucus, NJ, USA: Springer-Verlag New York, Inc."
  },
  {
    "objectID": "01-introduccion.html#qué-es-inferencia-causal",
    "href": "01-introduccion.html#qué-es-inferencia-causal",
    "title": "1  Introducción (Parte 1)",
    "section": "1.1 ¿Qué es inferencia causal?",
    "text": "1.1 ¿Qué es inferencia causal?\nLa inferencia causal consiste en predecir los posibles efectos de intervenciones, y entender qué pasaría si las condiciones que observamos fueran diferentes, es decir, condiciones contrafactuales. Tanto en ciencia como en industria, estos dos conceptos son muy importantes:\nIntervenciones (acciones):\n\n¿Qué efecto tiene sobre las ventas reducir el presupuesto de publicidad?\n¿Qué efecto tienen sobre la salud de una persona administrarle un medicamento?\n¿Cuáles son las expectativas de un hogar que ponemos en un programa gubernamental relacionado con la educación o la salud?\n\nContrafactuales (no necesariamente intervenciones que podemos controlar o ejecutar, sino escenarios hipotéticos):\n\n¿Cuánto ha contribuido a las ventas de un producto el gasto en publicidad?\n¿Cuál sería el ingreso de una persona si tuviera un año más de estudios?\n¿Cómo sería la salud de una persona que ha fumado durante 10 años si no hubiera fumado?\n\nEste tipo de preguntas centrales en la industria y la ciencia generalmente no pueden contestarse únicamente usando términos estadísticos y datos disponibles. Las razones son:\n\nAsociaciones entre variables observadas no implican relaciones causales entre las variables.\nLa ausencia de asociación entre variables observadas no implica que no hay relación causal entre ellas.\nRelaciones causales no están en los datos: están en el conocimiento experto o teoría científica.\n\nLa evaluación de intervenciones y de contrafactuales tienen una lógica similar, pero su naturaleza conceptual es diferente: en un caso"
  },
  {
    "objectID": "01-introduccion.html#preguntas-y-datos",
    "href": "01-introduccion.html#preguntas-y-datos",
    "title": "1  Introducción (Parte 1)",
    "section": "1.2 Preguntas y datos",
    "text": "1.2 Preguntas y datos\nPara entender y poder usar datos para contestar preguntas de interés, el paso inicial más importante es entender bajo que proceso se generan los datos. Veremos cómo estos procesos generadores se expresan en términos causales.\n\nCuanto más sepamos de este proceso, mejor podemos contestar preguntas de interés\nEn muchos casos, tenemos qué hacer supuestos basados en conocimiento experto acerca de este proceso generador para poder producir (o no) respuestas.\n\nEn particular, en inferencia causal:\n\nSi no tenemos los supuestos y hechos relevantes que definen el proceso generador de datos, no es posible dar respuestas a preguntas causales\n\n\nEjemplo (cálculos renales)\nEste es un estudio real acerca de tratamientos para cálculos renales (Julious y Mullee (1994)). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.\nLa tabla original tiene 700 renglones (cada renglón es un paciente)\n\ncalculos <- read_csv(\"../datos/kidney_stone_data.csv\")\nnames(calculos) <- c(\"tratamiento\", \"tamaño\", \"éxito\")\ncalculos <- calculos |> \n   mutate(tamaño = ifelse(tamaño == \"large\", \"grandes\", \"chicos\")) |> \n   mutate(resultado = ifelse(éxito == 1, \"mejora\", \"sin_mejora\")) |> \n   select(tratamiento, tamaño, resultado)\nnrow(calculos)\n\n[1] 700\n\n\ny se ve como sigue (muestreamos algunos renglones):\n\ncalculos |> \n   sample_n(10) |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    resultado \n  \n \n\n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    chicos \n    sin_mejora \n  \n  \n    A \n    chicos \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    grandes \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    grandes \n    mejora \n  \n\n\n\n\n\nAunque estos datos contienen información de 700 pacientes, los datos pueden resumirse sin pérdida de información contando como sigue:\n\ncalculos_agregada <- calculos |> \n   group_by(tratamiento, tamaño, resultado) |> \n   count()\ncalculos_agregada |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    resultado \n    n \n  \n \n\n  \n    A \n    chicos \n    mejora \n    81 \n  \n  \n    A \n    chicos \n    sin_mejora \n    6 \n  \n  \n    A \n    grandes \n    mejora \n    192 \n  \n  \n    A \n    grandes \n    sin_mejora \n    71 \n  \n  \n    B \n    chicos \n    mejora \n    234 \n  \n  \n    B \n    chicos \n    sin_mejora \n    36 \n  \n  \n    B \n    grandes \n    mejora \n    55 \n  \n  \n    B \n    grandes \n    sin_mejora \n    25 \n  \n\n\n\n\n\nComo en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:\n\ncalculos_agregada |> pivot_wider(names_from = resultado, values_from = n) |> \n   mutate(total = mejora + sin_mejora) |> \n   mutate(prop_mejora = round(mejora / total, 2)) |> \n   select(tratamiento, tamaño, total, prop_mejora) |> \n   arrange(tamaño) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    total \n    prop_mejora \n  \n \n\n  \n    A \n    chicos \n    87 \n    0.93 \n  \n  \n    B \n    chicos \n    270 \n    0.87 \n  \n  \n    A \n    grandes \n    263 \n    0.73 \n  \n  \n    B \n    grandes \n    80 \n    0.69 \n  \n\n\n\n\n\nEsta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Pero es apropiada para empezar a contestar la pregunta:\n\n¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?\n\nSupongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:\n\ncalculos |> group_by(tratamiento) |> \n   summarise(prop_mejora = mean(resultado == \"mejora\") |> round(2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    prop_mejora \n  \n \n\n  \n    A \n    0.78 \n  \n  \n    B \n    0.83 \n  \n\n\n\n\n\ny parece ser que el tratamiento \\(B\\) es mejor que el \\(A\\). Esta es una paradoja (un ejemplo de la paradoja de Simpson) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar \\(B\\)? ¿Si sabe debería recetar \\(A\\)? Esta discusión parece no tener mucho sentido.\nPodemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:\n\ncalculos |> group_by(tratamiento, tamaño) |> count() |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    n \n  \n \n\n  \n    A \n    chicos \n    87 \n  \n  \n    A \n    grandes \n    263 \n  \n  \n    B \n    chicos \n    270 \n  \n  \n    B \n    grandes \n    80 \n  \n\n\n\n\n\nNuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos. En este caso, hay una decisión pues A es una cirugía y B es un procedimiento menos invasivo, y se prefiere utilizar el tratamiento \\(A\\) para cálculos grandes, y \\(B\\) para cálculos chicos. Esto quiere decir que en la tabla total el tratamiento \\(A\\) está en desventaja porque se usa en casos más difíciles, pero el tratamiento \\(A\\) parece ser en general mejor. La razón es probablemente un proceso de optimización de recursos y riesgo que hacen los doctores.\n\nUna mejor respuesta a la pregunta de qué tratamiento es mejor es la que presenta los datos desagregados\nLa tabla desagregada de asignación del tratamiento nos informa acerca de cómo se está distribuyendo el tratamiento en los pacientes.\n\n\n\n\n\n\n\nNota\n\n\n\nLos resúmenes descriptivos acompañados de hipótesis causales acerca del proceso generador de datos, nos guía hacia descripciones interpretables de los datos.\n\n\nLas explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos.\nPodemos codificar la información causal con un diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    T \n    M \n    C\n  edge [minlen = 3]\n    T -> M\n    C -> T\n    C -> M\n{ rank = same; M; T }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEs decir, el tamaño de los cálculos es una causa común de tratamiento (T) y resultado (M). Veremos más adelante que la decisión de condicionar a el tipo de cálculos proviene de un análisis relativamente simple de este diagrama causal, independientemente de los métodos que usemos para estimar las proporciones de interés (en este ejemplo, examinar las tablas cruzadas es equivalente a hacer estimaciones de máxima verosimlitud).\n\n\nEjemplo (cálculos renales 2)\nContrastemos el ejemplo anterior usando exactamente la misma tabla de datos, pero con el supuesto de un proceso generador diferente. En este caso, los tratamientos son para mejorar alguna enfermedad del corazón. Sabemos que parte del efecto de este tratamiento ocurre gracias a una baja en presión arterial de los pacientes, así que después de administrar el tratamiento, se toma la presión arterial de los pacientes. Ahora tenemos la tabla agregada y desagregada como sigue:\n\ncorazon <- calculos |> \n  select(tratamiento, presión = tamaño, resultado) |> \n  mutate(presión = ifelse(presión == \"grandes\", \"alta\", \"baja\"))\ncorazon_agregada <- corazon |> \n   group_by(tratamiento, presión, resultado) |> \n   count()\ncorazon_agregada |> pivot_wider(names_from = resultado, values_from = n) |> \n   mutate(total = mejora + sin_mejora) |> \n   mutate(prop_mejora = round(mejora / total, 2)) |> \n   select(tratamiento, presión, total, prop_mejora) |> \n   arrange(presión) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    presión \n    total \n    prop_mejora \n  \n \n\n  \n    A \n    alta \n    263 \n    0.73 \n  \n  \n    B \n    alta \n    80 \n    0.69 \n  \n  \n    A \n    baja \n    87 \n    0.93 \n  \n  \n    B \n    baja \n    270 \n    0.87 \n  \n\n\n\n\n\n\ncorazon |> group_by(tratamiento) |> \n   summarise(prop_mejora = mean(resultado == \"mejora\") |> round(2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    prop_mejora \n  \n \n\n  \n    A \n    0.78 \n  \n  \n    B \n    0.83 \n  \n\n\n\n\n\n¿Cuál creemos que es el mejor tratamiento en este caso? ¿Deberíamos usar la tabla agregada o la desagregada por presión?\n\nEn este caso, la tabla agregada es más apropiada (B es mejor tratamiento).\nLa razón es que presión en este caso es una consecuencia de tomar el tratamiento, y como las tablas muestran, B es más exitoso en bajar la presión de los pacientes.\nSi sólo comparamos dentro de los grupos de presión baja o de presión alta, ignoramos lo más importante del tratamiento en la probabilidad de mejorar.\n\nNuestros supuestos causales podemos mostrarlos con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    P\n    T \n    M \n  edge [minlen = 3]\n    T -> P\n    P -> M\n    T -> M\n{ rank = same; M; T}\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\n\n\nEjemplo (admisiones de Berkeley)\nUna ejemplo al que regresaremos más adelante es el siguiente: en 1973 se recolectaron datos agregados de solicitantes para estudiar en Berkeley para los 6 departamentos más grandes, clasificados por sexo del solicitante y si fue admitido o no. Los resultados se muestran a continuación:\n\ndata(\"UCBAdmissions\")\nadm_original <- UCBAdmissions |> as_tibble() |> \n   pivot_wider(names_from = Admit, values_from = n) \nadm_original |> knitr::kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Gender \n    Dept \n    Admitted \n    Rejected \n  \n \n\n  \n    Male \n    A \n    512 \n    313 \n  \n  \n    Female \n    A \n    89 \n    19 \n  \n  \n    Male \n    B \n    353 \n    207 \n  \n  \n    Female \n    B \n    17 \n    8 \n  \n  \n    Male \n    C \n    120 \n    205 \n  \n  \n    Female \n    C \n    202 \n    391 \n  \n  \n    Male \n    D \n    138 \n    279 \n  \n  \n    Female \n    D \n    131 \n    244 \n  \n  \n    Male \n    E \n    53 \n    138 \n  \n  \n    Female \n    E \n    94 \n    299 \n  \n  \n    Male \n    F \n    22 \n    351 \n  \n  \n    Female \n    F \n    24 \n    317 \n  \n\n\n\n\n\ny las proporciones de admisión por sexo y departamente son las siguientes:\n\nadm_tbl <- adm_original |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected), 2), total = Admitted + Rejected) |> \n   select(Gender, Dept, prop_adm, total) |> \n   pivot_wider(names_from = Gender, values_from = prop_adm:total)\nadm_tbl |> knitr::kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Dept \n    prop_adm_Male \n    prop_adm_Female \n    total_Male \n    total_Female \n  \n \n\n  \n    A \n    0.62 \n    0.82 \n    825 \n    108 \n  \n  \n    B \n    0.63 \n    0.68 \n    560 \n    25 \n  \n  \n    C \n    0.37 \n    0.34 \n    325 \n    593 \n  \n  \n    D \n    0.33 \n    0.35 \n    417 \n    375 \n  \n  \n    E \n    0.28 \n    0.24 \n    191 \n    393 \n  \n  \n    F \n    0.06 \n    0.07 \n    373 \n    341 \n  \n\n\n\n\n\nComplementamos con las tasas de aceptación a total por género, y tasas de aceptación por departamento:\n\nadm_original |> group_by(Gender) |> \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Gender \n    Admitted \n    Rejected \n    prop_adm \n  \n \n\n  \n    Female \n    557 \n    1278 \n    0.30 \n  \n  \n    Male \n    1198 \n    1493 \n    0.45 \n  \n\n\n\n\n\nLa pregunta que queremos hacer es: ¿existe discriminación por sexo en la selección de candidatos? Examinando las tablas no está clara cuál es la respuesta.\n\nadm_original |> group_by(Dept) |> \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Dept \n    Admitted \n    Rejected \n    prop_adm \n  \n \n\n  \n    A \n    601 \n    332 \n    0.64 \n  \n  \n    B \n    370 \n    215 \n    0.63 \n  \n  \n    C \n    322 \n    596 \n    0.35 \n  \n  \n    D \n    269 \n    523 \n    0.34 \n  \n  \n    E \n    147 \n    437 \n    0.25 \n  \n  \n    F \n    46 \n    668 \n    0.06 \n  \n\n\n\n\n\nDiscutiremos este ejemplo con más detalle más adelante. La interpretación debe ser hecha con cuidado, y debemos establecer claramente los supuestos que fundamentan nuestra decisión de mostrar cada tabla y de qué forma mostrarlas."
  },
  {
    "objectID": "01-introduccion.html#resumen-de-ejemplos",
    "href": "01-introduccion.html#resumen-de-ejemplos",
    "title": "1  Introducción (Parte 1)",
    "section": "1.3 Resumen de ejemplos",
    "text": "1.3 Resumen de ejemplos\nNótese que en los dos casos anteriores, los datos son exactamente los mismos, pero la respuesta correcta es diferente en cada caso. En la tabla de datos no está la respuesta acerca de qué resumen es el correcto. Solamente conocimiento externo de cómo se generan los datos sugieren cómo debemos tratar y explicar lo que observamos en cada caso.\nA se conocimiento externo es una combinación de\n\nConocimiento de dominio o teorías científicas, y\nEntendimiento de cómo fueron recolectados y procesados los datos, lo cual también es información causal.\n\nEstos ejemplos también muestran adicionalmente que:\n\nIncluso desde un punto de vista puramente descriptivo, es necesario entender algo de la estructura causal del problema para poder dar descripciones interpretables\nSi no tenemos la información correcta, es difíl producir estimaciones causales.\n\nEn el primer ejemplo de cálculos renales fue importante saber saber el hecho de que los doctores seleccionaban el tratamiento según la severidad y que tuviéramos una medición de esa variable. En el segundo ejemplo de presión no era necesaria esa medición adicional.\n\nMás adelante hablaremos de experimentación. Veremos que aquí también entender el proceso generador de datos es importante. Por ejemplo, ¿qué variables podemos usar cómo controles para mejorar la estimación y qué variables no?\nModelos causales nos ayudan a diseñar estudios (experimentales o no) y a decidir qué datos es necesario recolectar."
  },
  {
    "objectID": "01-introduccion.html#más-de-asociación-no-causal",
    "href": "01-introduccion.html#más-de-asociación-no-causal",
    "title": "1  Introducción (Parte 1)",
    "section": "1.4 Más de asociación no causal",
    "text": "1.4 Más de asociación no causal\nDiscutiremos otro ejemplo de los puntos mencionados arriba.\nAlgunos estudios fueron publicados en la primera mitad de 2020 que notaban que el porcentaje fumadores entre los casos positivos de COVID era menor que en la población general, y se hicieron algunas interpretaciones acerca de este hecho. Estos estudios se hicieron con personas que se hicieron una prueba.\nEn este ejemplo replicaremos cómo es que podemos encontrar esta asociación en este tipo de estudios aún cuando no exista tal asociación en la población general (ver este artículo). Usaremos datos sintéticos (simulados).\nPrimero vamos a razonar acerca del proceso generador de datos y a hacer algunos supuestos:\n\nEn primer lugar, ¿cuándo decide hacerse alguien una prueba? A principios de 2020, son principalmente personas que tienen síntomas considerables, y trabajadores de salud (tengan o no síntomas).\nSer trabajador de salud incrementa el riesgo de contagiarse.\nEn algunos países, fumar está asociado con ser trabajador de salud (no tienen la misma tasa de tabaquismo que la población general).\nSólo observamos a las personas que se hicieron una prueba.\nFumar no tiene efectos causales en este modelo.\nIngoramos por el momento que la relación entre covid y prueba positiva no es perfecta.\n\nPodemos resumir cualitativamente con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Prueba\n    TrabSalud\n    Síntomas\n    Fumar\n    Covid\n  edge [minlen = 3]\n    #TrabSalud -> Covid\n    TrabSalud -> Prueba\n    TrabSalud -> Fumar\n    TrabSalud -> Covid\n    U -> Síntomas\n    Covid -> Síntomas\n    Síntomas -> Prueba\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nEl código para simular es el siguiente: todas las variables toman valores 0 o 1, pero con diferentes probabilidades y dependiendo de las variables que son padres en la gráfica de arriba.\n\nSimulamos un millón de personas de las cuales aproximadamente el 1% son trabajadores de salud.\nSuponemos que la probabilidad es de 5% de que un trabajador de salud resulte positivo y de 1% para el del resto de las personas.\nSuponemos que de las personas que tienen covid, el 50% tienen síntomas y de las personas que no tienen covid, el 1% tiene síntomas.\nSuponemos que de los trabadores de salud el 99% se hicieron prueba (sin importar si tenían o no síntomas) y el resto de las personas se divide en 2, de los no trabadores de salud con síntomas, el 85% se hicieron una prueba y de los no trabajdores de salud sin síntomas, el 1% se hizo una prueba\nDe los trabajadores de salud, el 20% fuman, del resto de las personas el 7% fuman.\n\n\n\nCódigo\nset.seed(8221)\n#simular población\nn <- 1e6\ntrab_salud <- rbinom(n, 1, 0.01)\ncovid <- rbinom(n, 1, ifelse(trab_salud==1, 0.05, 0.01))\ndatos <- tibble(trab_salud = trab_salud, covid) |> \n  mutate(sintomas = rbernoulli(n, ifelse(covid == 1, 0.5, 0.01))) |> \n  mutate(prueba = rbernoulli(n, ifelse(trab_salud ==1, 0.99, 0.84 * sintomas + 0.01))) |> \n  mutate(fumar = rbernoulli(n, ifelse(trab_salud == 1, 0.20, 0.07))) |> \n  mutate(covid = ifelse(covid ==1, \"positivo\", \"negativo\")) |> \n  mutate(fumar = ifelse(fumar, \"fuma\", \"no_fuma\"))\n\n\nSuponemos ahora que tomamos como muestra a todas aquellas personas que se hicieron una prueba. En primer lugar, la proporción de fumadores en la muestra es un poco más alta que la población, porque los trabajadores de salud están sobrerrepresentados:\n\ndatos_pruebas <- filter(datos, prueba == 1)\ntable(datos_pruebas$fumar) |> prop.table() |> round(2)\n\n\n   fuma no_fuma \n   0.11    0.89 \n\n\nY ahora vemos que bajo esta condición o filtro, están asociados fumar y tener covid:\n\ntable(datos_pruebas$covid, datos_pruebas$fumar) |> prop.table(margin = 2) |> \n  round(2) \n\n          \n           fuma no_fuma\n  negativo 0.90    0.85\n  positivo 0.10    0.15\n\n\nSin embargo, en la población (sin filtrar por los que se hicieron prueba) en general, esperaríamos una asociación positiva pero relativamente chica de fumar con tener covid (veremos por qué sabemos esto al consultar el diagrama):\n\ntable(datos$covid, datos$fumar) |> prop.table(margin = 2) |> \n  round(4)\n\n          \n             fuma no_fuma\n  negativo 0.9892  0.9896\n  positivo 0.0108  0.0104\n\n\nEsta tampoco es una relación causal. Discutiremos con detalle más adelante por qué condicionar a sólo los que hicieron una prueba produce una correlación fuerte entre estas dos variables que no están causalmente relacionadas.\n\n\n\n\nJulious, Steven A, y Mark A Mullee. 1994. «Confounding and Simpson’s paradox». BMJ 309 (6967): 1480-81. https://doi.org/10.1136/bmj.309.6967.1480."
  },
  {
    "objectID": "02-modelos-graficos.html#repaso-de-probabilidad",
    "href": "02-modelos-graficos.html#repaso-de-probabilidad",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.1 Repaso de probabilidad",
    "text": "2.1 Repaso de probabilidad\nSi \\(X\\) es una variable aleatoria, abusaremos de la notación escribiendo \\(p(x)\\) para denotar su función de densidad (continua o discreta). Si \\(X\\) es discreta, \\(p(x)=P(X=x)\\), y si \\(X\\) es continua, entonces \\(p(x)\\) es la función de densidad, que utilizamos para calcular probabilidades usando integrales, por ejemplo\n\\[P(X \\in [a,b]) = \\int_a^b p(x)\\, dx\\] Ojo: en algunos casos, para evitar reescribir fórmulas, usaremos esta misma notación para denotar probabilidades de variables discretas, que más apropiadamente escribiríamos como \\(P(X\\in[a,b]) = \\sum_{x=a}^{b} P(X = x)\\).\nSi \\(X\\) y \\(Y\\) son variables aleatorias, entonces denotamos por \\(p(x,y)\\) a su densidad conjunta. Podemos calcular las distribuciones de x y y integrando sobre una de las variables\n\\[p(y) = \\int_{-\\infty}^{\\infty} p(x,y)dx = \\int p(x,y)dx\\] Nótese que abusamos algo de la notación quitando los límites de la integral de la derecha (y recordamos que si \\(X\\) es discreta, entonces usamos una suma en lugar de una integral). En este contexto, \\(p(x), p(y)\\) se llaman distribuciones marginales de \\(X\\) y \\(Y\\)\nDenotamos por \\(p(y|x)\\) y \\(p(x|y)\\) a las densidades condicionales de Y dado X y X dada Y respectivamente. Estas están definidas por\n\\[p(y|x) = \\frac{p(x, y)}{p(x)}\\] Esta densidad condicional nos dice cómo se distribuye \\(Y\\) cuando sabemos que \\(X=x\\).\nDe esta definición, tenemos la regla del producto que establece que\n\\[p(x,y) = p(y|x) p(x) = p(x|y)p(y) \\]\nCuando la distribución condicional de \\(p(y|x)\\) cambia dependiendo de la \\(x\\), decimos que \\(X\\) y \\(Y\\) está asociadas. Si no es el caso, decimos que son independientes. Esto quiere decir que\n\\[p(y|x) = p(y)\\] es decir, la condicional de \\(Y\\) dada \\(X\\) es igual a la marginal de \\(Y\\). Por definición, la independencia también se puede escribir como una versión simplificada de la regla del producto:\n\\[p(x,y) = p(x)p(y)\\] es decir, la conjunta se factoriza en una parte que sólo depende de \\(x\\) y otra que sólo dependen de \\(y\\).\n\n\n\n\n\n\nTip\n\n\n\nUna manera útil de construir modelos de probabilidad conjuntas con variables que tienen dependencias es utilizando una factorización de la regla del producto, lo cual nos permite concentrarnos en una variable a la vez.\n\n\nDependiendo del tipo de problema, puede ser más conveniente definir \\(p(x)\\) y \\(p(y|x)\\) o \\(p(y)\\) y \\(p(x|y)\\). En ambos casos podemos calcular la conjunta \\(p(x,y)\\) con la que podemos calcular cualquier probabilidad conjunta de interés o cantidad resumen que involucra a a estas dos variables aleatorias.\n\nEjemplo 1\nSupongamos que \\(X\\) es el resultado de una tirada de dado, y que \\(Y\\) es el número de soles que obtenemos en \\(X\\) volados de una moneda justa.\nEntonces podemos escribir \\(p(x) = 1/6\\) para \\(x=1,2,\\ldots, 6\\), es decir, \\(X\\) es Uniforme en \\(\\{1,2,3,4,5,6\\}\\), y \\(Y|X=x\\) son el número de soles en \\(x\\) volados, de modo que es Binomial con parámetros \\((x, 0.5)\\). Esto lo podemos escribir como\n\\[\\begin{equation}\n\\begin{split}\nY|X \\sim & Bin(X, 0.5) \\\\\nX  = & U(\\{1,2,3,4,5,6\\})\n\\end{split}\n\\end{equation}\\]\nEstas variables no son independientes, pues la condicional de \\(Y\\) cambia dependiendo del valor que toma \\(X\\).\nComo estas dos variables son discretas, la conjunta puede escribirse con la regla del producto como una tabla como sigue:\n\nprobs_x <- tibble(x = 1:6, p_x = 1/6)\nprobs_conjunta <-  crossing(probs_x, y = seq(0, 6, 1)) |> \n  mutate(p_cond_y = dbinom(y, size = x, prob = 0.5)) |> \n  mutate(p = p_cond_y * p_x) #producto\nprobs_conjunta |> select(x, y, p) |> \n  pivot_wider(names_from = x, values_from = p, names_prefix = \"x=\") |> \n  kable(digits = 4) |> kable_paper()\n\n\n\n \n  \n    y \n    x=1 \n    x=2 \n    x=3 \n    x=4 \n    x=5 \n    x=6 \n  \n \n\n  \n    0 \n    0.0833 \n    0.0417 \n    0.0208 \n    0.0104 \n    0.0052 \n    0.0026 \n  \n  \n    1 \n    0.0833 \n    0.0833 \n    0.0625 \n    0.0417 \n    0.0260 \n    0.0156 \n  \n  \n    2 \n    0.0000 \n    0.0417 \n    0.0625 \n    0.0625 \n    0.0521 \n    0.0391 \n  \n  \n    3 \n    0.0000 \n    0.0000 \n    0.0208 \n    0.0417 \n    0.0521 \n    0.0521 \n  \n  \n    4 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0104 \n    0.0260 \n    0.0391 \n  \n  \n    5 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0052 \n    0.0156 \n  \n  \n    6 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0026 \n  \n\n\n\n\n\nNótese adicionalmente que la forma en que planteamos el problema naturalmente nos da un modelo generativo, es decir, podemos simular fácilmente realizaciones de esta conjunta particular:\n\nsimular_juego <- function(n = 1, x = NULL){\n  if(is.null(x)){\n    x <- sample(1:6, n, replace = TRUE)\n  }\n  y <- rbinom(n, x, prob = 0.5)\n  tibble(n = seq_len(n), x = x, y = y)\n}\nset.seed(880)\nsimular_juego(n = 5)\n\n# A tibble: 5 × 3\n      n     x     y\n  <int> <int> <int>\n1     1     5     3\n2     2     5     1\n3     3     3     1\n4     4     6     4\n5     5     4     3\n\n\nY usando simulación podemos estimar cualquier cantidad de interés acerca de las variables \\(X\\) y \\(Y\\). Por ejemplo, su correlación la estimamos con\n\nsimular_juego(n = 10000) |> select(x, y) |> cor()\n\n          x         y\nx 1.0000000 0.6716973\ny 0.6716973 1.0000000\n\n\n\n\nEjemplo 2\nSupongamos que \\(W\\) es una el peso de una persona y \\(H\\) su estatura. Podemos comenzar con la factorización \\(p(w,h) = p(h)p(w|h)\\). Un modelo generativo podría ser el que sigue: \\(H\\) es Normal con media 165 y desviación estandar 12,\n\\[H \\sim N(170, 12) \\]\ny dada la estatura \\(H=h\\), el peso es\n\\[W|H=h \\sim N(m_h, 10)\\] donde\n\\[m_h = -50 + 0.7 h\\]\n\nsim_wh <- function(n = 10){\n  h <- rnorm(n, 170, 12)\n  m_h <- -50 + 0.7 * h\n  w <- rnorm(n, m_h, 10)\n  tibble(w = w, h = h)\n}\n\n\nset.seed(992)\nsims <- sim_wh(500)\nggplot(sims, aes(x = h, y = w)) + geom_point()"
  },
  {
    "objectID": "02-modelos-graficos.html#caso-multivariado",
    "href": "02-modelos-graficos.html#caso-multivariado",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.2 Caso multivariado",
    "text": "2.2 Caso multivariado\nSupongamos que tenemos \\(X_1,\\ldots, X_p\\) variables aleatorias. Denotamos su conjunta con \\[p(x_1, x_2, \\ldots, x_n)\\] En el caso particular de 3 variables p(x,y,z) la regla del producto se escribe como\n\\[p(x,y,z) = p(z|x,y)p(y|z)p(x)\\] que podemos escribir, dependiendo del problema, en cualquiera de las seis permutaciones posibles, por ejemplo:\n\\[p(x,y,z) = p(x|y,z)p(y|z)p(z)\\]\nEl proceso de simulación lo podemos mostrar gráficamente como sigue:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X \n    Y \n    Z\n  edge [minlen = 3]\n    Z -> Y\n    Y -> X\n    Z -> X\n{ rank = same; Z; Y }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nNótese que este ejemplo puede aplicarse a cualquier conjunta nos interese, pues la factorización resulta de la regla del producto.\n\n2.2.1 Ejemplo\nSupongamos que escogemos al azar un número \\(X\\) entre 0 y 1, y luego tiramos dos veces cinco volados con probabilidad de sol \\(X\\). Medimos el número de soles en cada prueba como \\(S_1\\) y \\(S_2\\).\nEn este caso, es natural escribir la factorización:\n\\[p(x,s_1,x_2) = p(s_2|s_1,x)p(s_1|x)p(x).\\] Sin embargo, podemos simplificar aún más esta conjunta, pues en realidad una vez que sabemos X, el resultado de \\(S_1\\) no cambia la distribución de \\(S_2\\), de forma que para el proceso que describimos arriba,\n\\[p(x, s_1, s_2) = p(s_2|x)p(s_1|x)p(x).\\] En este caso, en nuestros supuestos está la independencia condicional de \\(S_1\\) y \\(S_2\\) dado \\(X\\), que explicaremos con detalle más adelante. El diagrama relevante es\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X \n    S1 [label = <S<SUB>1</SUB>>]\n    S2 [label = <S<SUB>2</SUB>>]\n  edge [minlen = 3]\n    X -> S1\n    X -> S2\n{ rank = same; S1; S2 }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nY podemos hacer simulaciones de este proceso generador:\n\nsimular_dos <- function(n = 10, x = NULL){\n  if(is.null(x)){\n    x <- runif(n)\n  }\n  s_1 <- rbinom(n, 5, prob = x)\n  s_2 <- rbinom(n, 5, prob = x)\n  tibble(x = x, s_1 = s_1, s_2 = s_2)\n}\nset.seed(116)\nsims_monedas <- simular_dos(5000)\nhead(sims_monedas)\n\n# A tibble: 6 × 3\n      x   s_1   s_2\n  <dbl> <int> <int>\n1 0.741     4     4\n2 0.336     5     2\n3 0.193     1     1\n4 0.281     1     2\n5 0.998     5     5\n6 0.534     3     5\n\n\nNótese que aún cuando simulamos independientemente \\(S_1\\) y \\(S_2\\) una vez que tenemos el dado, \\(S_1\\) y \\(S_2\\) no son independientes:\n\nggplot(sims_monedas, aes(x = s_1, y = s_2)) + geom_jitter(width = 0.25, height = 0.25)\n\n\n\n\n\nCuando no conocemos \\(X\\), saber \\(S_1\\) nos da información acerca de \\(S_2\\), porque saber \\(S_1\\) cambia la distribución de \\(X\\) (cuál es la probablidad de sol)\nSi no conocemos \\(X\\), la información puede fluir de \\(S_1\\) a \\(S_2\\)."
  },
  {
    "objectID": "02-modelos-graficos.html#variables-observadas-y-no-observadas",
    "href": "02-modelos-graficos.html#variables-observadas-y-no-observadas",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.3 Variables observadas y no observadas",
    "text": "2.3 Variables observadas y no observadas\nNótese que en muchos casos, la estructura que genera los datos puede incluir variables que no hemos medido. No es una buena idea quitar estas variables porque simplemente nos las conocemos. Dado el proceso generador, no tendría mucho sentido escribir \\(S_1 \\to S_2\\) o \\(S_2 \\to S_1\\) (aunque podríamos construir tales modelos).\nEn este caso, podríamos mejor escribir:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    X\n  node [shape=plaintext]\n    S1 [label = <S<SUB>1</SUB>>]\n    S2 [label = <S<SUB>2</SUB>>]\n  edge [minlen = 3]\n    X -> S1\n    X -> S2\n{ rank = same; S1; S2 }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nLa estructura del modelo junto con la naturaleza de las relaciones que conocemos nos permite hacer inferencia sobre esas variables no observadas:\n\nmod_monedas <- cmdstanr::cmdstan_model(\"../src/monedas.stan\")\nprint(mod_monedas)\n\ndata {\n  int<lower=0> s_1;\n  int<lower=0> s_2;\n}\nparameters {\n  real<lower=0, upper = 1> x;\n}\nmodel {\n  x ~ uniform(0, 1);\n  s_1 ~ binomial(5, x);\n  s_2 ~ binomial(5, x);\n}\n\n\n\ndatos_lista <- list(s_1 = 5, s_2 = 3)\najuste <- mod_monedas$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.7 seconds.\n\nsims <- ajuste$draws(c(\"x\"), format = \"df\")\nresumen <- ajuste$summary(c(\"x\"))\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable  mean    q5   q95\n  <chr>    <dbl> <dbl> <dbl>\n1 x        0.749 0.516 0.921\n\n\nDe modo que con alta probabilidad, escogimos una \\(X\\) entre .5 y 0.93.\n\n2.3.1 Ejemplo (estudio de Santa Clara)\nEn 2020 se hizo un estudio de seroprevalencia de COVID en Santa Clara, California.\nSe tomó una muestra de individuos (ver los detalles en el artículo original). Para propósitos de este análisis supondremos que la muestra puede considerarse como aleatoria simple.\nSe obtuvieron 3,300 individuos, y 50 de ellos resultaron con prueba positiva (1.5%). Sin embargo, el kit de prueba que estaban utilizando, tienen cierta especificidad y sensibilidad menores a 1. En pruebas de gold standard, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas.\nConstuiremos ahora una gráfica que indica cómo es el proceso generador de datos\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    sens\n    esp\n    prev\n    Inf\n  node [shape=plaintext]\n    Inf\n    Positivos\n    npos\n    poskit\n    nneg\n    negkit\n    N\n    \n  edge [minlen = 3]\n    npos -> poskit\n    sens -> poskit\n    nneg -> negkit\n    esp -> negkit\n    prev -> Inf\n    Inf -> Positivos\n    sens -> Positivos\n    esp -> Positivos\n    N -> Inf\n    \n}\n\", width = 150, height = 60)\n\n\n\n\n\n\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\nmod_sc <- cmdstan_model(\"../src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n;\n  int<lower=0> kit_pos;\n  int<lower=0> n_kit_pos;\n  int<lower=0> kit_neg;\n  int<lower=0> n_kit_neg;\n}\n\nparameters {\n  real<lower=0, upper=1> p; //seroprevalencia\n  real<lower=0, upper=1> sens; //sensibilidad\n  real<lower=0, upper=1> esp; //especificidad\n}\n\ntransformed parameters {\n  real<lower=0, upper=1> prob_pos;\n\n  prob_pos = p * sens + (1 - p) * (1 - esp);\n\n}\nmodel {\n  // verosimilitud\n  n ~ binomial(N, prob_pos);\n  // info de kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales,\n  p ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\n\nn <- 50\nN <- 3300\ndatos_lista <- list(N = 3300, n = 50,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste <- mod_sc$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"p\", \"sens\", \"esp\"), format = \"df\")\nresumen <- ajuste$summary(c(\"p\"))\n\n\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean      q5    q95\n  <chr>     <dbl>   <dbl>  <dbl>\n1 p        0.0102 0.00238 0.0173\n\n\nY podemos graficar la posterior de la seroprevalencia:\n\nggplot(sims, aes(x = p)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nY vemos que los datos son consistentes con el dato reportado por los autores (alrededor de 1.2%), pero que no podemos excluir valores de prevalencia muy bajos (por abajo de 0.3% por ejemplo). Por otro lado, también son consistentes valores muy altos de seroprevalencia, de manera que este estudio resultó ser poco informativo de la IFR del COVID.\nPodemos hacer diagnósticos adicionales acerca de la razón de esta variabilidad alta, si graficamos la relación entre especificidad de la prueba y estimación de prevalencia:\n\nggplot(sims, aes(x = esp, y = p)) + geom_point() +\n  xlab(\"Especificidad del kit\") + ylab(\"Prevalencia\")\n\n\n\n\nLa asociación entre estas dos cantidades es interesante porque ninguna depende directamente de la otra (o lo largo de una cadena): su asociación aparece porque son causas que compiten para explicar una observación."
  },
  {
    "objectID": "02-modelos-graficos.html#independencia-condicional",
    "href": "02-modelos-graficos.html#independencia-condicional",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.4 Independencia condicional",
    "text": "2.4 Independencia condicional\n\n\n\n\n\n\nIndepencia condicional\n\n\n\nSean \\(X,Y,Z\\) variables aleatorias. Decimos que \\(X\\) y \\(Y\\) son condicionalmente independientes cuando satisfacen \\[p(x,y|z) = p(x|z)p(y|z)\\] o equivalentemente, \\[p(x|y,z) = p(x|z)\\]\n\n\nEn palabras: si conocemos el valor de \\(Z\\), \\(X\\) y \\(Y\\) ya no están asociadas, o si ya condicionamos a z, entonces condicionar adicionalmente a \\(Y\\) no cambia la distribución condicional de \\(X\\). Para ver por qué las dos formas son equivalentes recuerda que cualquier regla de probabilidad general puede condicionarse a cualquier infromación y sigue siendo una regla válida. Como de mostramos que \\(p(x,y) = p(x)p(y)\\) si y sólo si \\(p(y|x) = p(y)\\), podemos obtener una regla válida condicionando todo a \\(Z\\).\nEn nuestro primer ejemplo de la sección anterior, observamos que una vez que sabíamos \\(X\\), la probabilidad de sol, no hay relación entre \\(X\\) y \\(Y\\), aún cuando no es cierto que \\(p(x,y) = p(x)p(y)\\).\nPodemos checar esto en las simulaciones, por ejemplo:\n\nset.seed(812)\nsimular_dos(1e5, x = 0.4) |> \n  select(s_1, s_2) |> \n  group_by(s_1, s_2) |> \n  count() |> \n  group_by(s_1) |> \n  mutate(prop_cond = n / sum(n)) |> \nggplot(aes(x = s_2, y = prop_cond, colour = s_1, group = factor(s_1))) +\n  geom_line()\n\n\n\n\nLas condicionales son iguales, de modo que son independientes dado \\(x = 0.4\\)."
  },
  {
    "objectID": "02-modelos-graficos.html#gráficas-dirigidas-acíclicas",
    "href": "02-modelos-graficos.html#gráficas-dirigidas-acíclicas",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.5 Gráficas dirigidas acíclicas",
    "text": "2.5 Gráficas dirigidas acíclicas\nPara representar la construcción de modelos que hemos considerado de manera gráfica, podemos usar las siguiente idea:\n\n\n\n\n\n\nNota\n\n\n\nDecimos que una gráfica dirigida \\(G\\) representa a una conjunta \\(p(x_1,\\ldots, x_p)\\) cuando podemos factorizar\n\\[p(x_1,\\ldots, x_p) = \\prod_{i=1}^p p(x_i | pa(x_i))\\]\ndonde \\(pa(x_i)\\) son los padres del nodo X_i en la gráfica G.\n\n\n\n2.5.0.1 Ejemplo\nConsideramos la siguiente gráfica:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Ob\n    Fuma\n    EC \n    Tos\n  edge [minlen = 3]\n   Ob -> EC\n   Fuma -> EC\n   Fuma -> Tos\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEsta gráfica representa una conjunta \\(p(o,f,c,t)\\) cuando es posible factorizar\n\\[p(o,f,c,t) = p(f)p(o)p(c|o,f)p(t|f),\\]\nde forma que podemos entender el proceso generador de este conjunto de variables como sigue: simulamos primero \\(F\\) y \\(C\\), usando el valor de \\(F\\) podemos simular \\(T\\), y usando el valor de \\(F\\) y \\(C\\) podemos simular \\(C\\). En este ejemplo podemos pensar que las variables son Obesidad, Fumador, Enfermedad de Corazón y Tos. Nótese que la distribución de Enfermedad de Corazón depende del estado de Obesidad y fumador. La probabilidad de tener tos depende directamente del estado de fumador.\nEl conjunto de independencias condicionales de una conjunta \\(p\\) está fuertemente ligado a la estructura de la gráfica que la representa:\n\n\n\n\n\n\nNota\n\n\n\nUna distribución \\(p\\) es representada por \\(G\\) si y sólo si para cada variable \\(W\\), cuando condicionamos a los padres \\(pa(W)\\) de \\(W\\), \\(W\\) es condicionalmente independiente de todas las variables que nos descendientes o padres de \\(W\\).\n\n\nEs decir, si condicionamos a los padres de una variable, esta variable es condicionalmente independiente de “el pasado”. Estas no son las únicas independencias condicionales que están presentes, veremos que para calcular éstas es necesario usar el concepto de d-separación. Antes discutiremos las estructuras básicas que nos interesan en una gráfica."
  },
  {
    "objectID": "02-modelos-graficos.html#estructuras-básicas-en-dags",
    "href": "02-modelos-graficos.html#estructuras-básicas-en-dags",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.6 Estructuras básicas en DAGs",
    "text": "2.6 Estructuras básicas en DAGs\nVeremos que para razonar acerca de las asociaciones e independencias que pueden aparecer en una conjunta, podemos examinar la gráfica que la represente, o dicho de otra manera, entender bajo qué condiciones puede propagarse información de un nodo a otro.\nConsideremos entonces tres variables \\(X\\), \\(Y\\) y \\(Z\\). Las tres estructuras que tenemos que entender en primer lugar son:\n\n2.6.1 Razonamiento de mediación\nEn este caso tenemos:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   X -> Z\n   Z -> Y\n}\n\", width = 150, height = 20)\n\n\n\n\n\n\nEn este caso,\n\nExiste asociación entre \\(X\\) y \\(Y\\).\nSi condicionamos a un valor de \\(Z\\), \\(X\\) y \\(Y\\) son condicionalmente independientes.\n\nPodemos pensar en \\(Z\\) como un mediador del efecto de \\(X\\) sobre \\(Y\\). Si no permitimos que \\(Z\\) varíe, entonces la información de \\(X\\) no fluye a \\(Y\\).\nPor ejemplo, si \\(X\\) tomar o no una medicina para el dolor de cabeza, \\(Z\\) es dolor de cabeza y \\(Y\\) es bienestar general, \\(X\\) y \\(Y\\) están relacionadas. Sin embargo, si condicionamos a un valor fijo de dolor de cabeza, no hay relación entre tomar la medicina y bienestar general.\n\n\n2.6.2 Razonamiento de causa común\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   Z -> X\n   Z -> Y\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso,\n\n\\(X\\) y \\(Y\\) tienen asociación\nSi condicionamos a \\(Z\\), entonces \\(X\\) y \\(Y\\) son condicionalmente independientes.\n\nEn este caso, variación en \\(Z\\) produce variación conjunta de \\(X\\) y \\(Y\\).\nEste tipo de estructura también se llama bifurcación, o decimos que \\(Z\\) es una variable de confusión.\nPor ejemplo, podríamos encontrar que el uso de aspirina \\(X\\) está asociado a una mortalidad más alta \\(Y\\). Una causa común es enfermedad grave que produce dolor (\\(Z\\)). Sin embargo, si condicionamos a personas sanas, veríamos que no hay relación entre uso de aspirina y mortalidad, igualmente veríamos que entre las personas enfermas el uso de aspirina no les ayuda a vivir más tiempo.\n\n\n2.6.3 Razonamiento de causas alternativas\nEn este caso, a \\(Z\\) también le llamamos un colisionador:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   X -> Z\n   Y -> Z\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\n\nEn este caso \\(X\\) y \\(Y\\) son independientes\nSin embargo, si condicionamos a \\(Z\\) entonces \\(X\\) y \\(Y\\) están asociados.\n\nEn este caso, si observamos un valor particular de \\(Z\\), entonces existen menos posibles configuraciones probables de \\(X\\) y \\(Y\\), y esto generalmente produce dependencia.\nPor ejemplo, si observamos que el pasto está mojado, entonces saber que no llovió implica que probablemente se encendieron los aspersores.\nPodríamos considerar las variables apariencia física \\(X\\) y capacidad intelectual \\(Y\\). En principio, estas dos variables podrían ser independientes en la población general. Sin embargo, si consideramos solamente aquellas personas famosas, encontraríamos una correlación negativa entre apariencia y capacidad."
  },
  {
    "objectID": "99-referencias.html",
    "href": "99-referencias.html",
    "title": "Referencias",
    "section": "",
    "text": "Bishop, Christopher M. 2006. Pattern Recognition and Machine\nLearning (Information Science and Statistics). Secaucus, NJ, USA:\nSpringer-Verlag New York, Inc.\n\n\nJulious, Steven A, and Mark A Mullee. 1994. “Confounding and\nSimpson’s Paradox.” BMJ 309 (6967):\n1480–81. https://doi.org/10.1136/bmj.309.6967.1480."
  }
]